{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2sL_PBxgR3cX",
        "o1YJUL7mR5uM",
        "qSyjislKYMeb",
        "OhM6DQpYDtmg",
        "yXzQVeMwLG0N",
        "3bJdwwihMP_N",
        "yekgXlchMUIm",
        "l73U37vYMYZJ",
        "SfS5cQLBMbTg",
        "SM4GMWnPMd5h",
        "N5L-I4VesBBq",
        "z4XdDlUcLeqX",
        "_9Yzd4xbxr6g",
        "AuqAjTW7WKuk",
        "z4AvIc69M7YZ",
        "7N7u4_nTM9U4",
        "t9rkp4QvM_J3",
        "wdK1Jj_iNEk5",
        "70xCikWMNIMJ",
        "fsMF4lbAImMr",
        "NKcDRmDjNaTm",
        "U-nYyJ-MNdS8",
        "HDPGlUbENgep",
        "AMqjHdP0Nia-",
        "kiOuhVCZNkgd",
        "Ev7JpXAb2IO-",
        "47zcDXycLUno",
        "OPPmQa6ILudV",
        "u2WkQAe2R9H7",
        "VepCaPSWXC8l",
        "PJ5DClm2bcsQ",
        "bhSnSlWDqDEe",
        "JzvdHXx0dLCn",
        "fFRuxnGUwEu2",
        "wZmT_n1-xGzO",
        "VU2fOeqU6fSM",
        "Ae6QXn-z7QkY",
        "ouhgBw0h9qrs",
        "H_0Awucf-mLH",
        "7CaoZe6KBGRW",
        "xwRfmTN3Bc5s",
        "sJAC-BGHCg5m",
        "th7-vAcvHaIG",
        "4z3JPO_pJd7o",
        "GiOuNwM2Kqs3",
        "Thruzq_DMFWP",
        "Lwc5paK6MXTt",
        "XfZfQsj6Nd96",
        "AugBSHhBOqaN",
        "gMyzFqRRRM-v",
        "O0gumSQemZVv",
        "h3Pop11ta57E",
        "DiXZK73fbdDF",
        "z2a_z7KJw9Cl",
        "fdJbSXyc3rgd",
        "BLydUfINKYlP",
        "ejYPjkMUVdbA",
        "xQisR0V3pKos",
        "AXnwq9LNbFiF",
        "8DlFaU-pnj-2",
        "BHXgufuw3ALm",
        "fR4MtOZrRfje",
        "zqpWkOIRV5KD"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pybaseball\n",
        "!pip install catboost\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2j5yaq0m0DWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0212W9tFcf9e"
      },
      "outputs": [],
      "source": [
        "import polars as pl\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from pybaseball import statcast, team_game_logs, retrosheet, playerid_lookup\n",
        "import pybaseball\n",
        "from google.colab import files\n",
        "\n",
        "from sklearn.model_selection import cross_val_predict, cross_val_score, KFold, StratifiedKFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score, log_loss\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "from catboost import CatBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "import arviz as az\n",
        "import pymc as pm\n",
        "import pickle\n",
        "\n",
        "pl.Config(tbl_cols=1000)\n",
        "pl.Config(tbl_rows=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collecting"
      ],
      "metadata": {
        "id": "2sL_PBxgR3cX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_2021 = statcast('2021-04-01', '2021-10-03')\n",
        "data_2021.to_csv('df_2021.csv')\n",
        "files.download('df_2021.csv')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SNJiTHE1ZmH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2022 = statcast('2022-04-07', '2022-10-02')\n",
        "data_2022.to_csv('df_2022.csv')\n",
        "files.download('df_2022.csv')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IlTvw1wd9qKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2023 = statcast('2023-03-30', '2023-10-01')\n",
        "data_2023.to_csv('data_2023.csv')\n",
        "files.download('data_2023.csv')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "No8q2tqp_iRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2024 = statcast('2024-03-28', '2024-09-29')\n",
        "data_2024.to_csv('df_2024.csv')\n",
        "files.download('df_2024.csv')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ySpdHd1DE6ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2021 = pl.read_csv('/content/drive/MyDrive/Datasets/stuff/df_2021.csv')\n",
        "data_2022 = pl.read_csv('/content/drive/MyDrive/Datasets/stuff/df_2022.csv')\n",
        "data_2023 = pl.read_csv('/content/drive/MyDrive/Datasets/stuff/data_2023.csv')\n",
        "data_2024 = pl.read_csv('/content/drive/MyDrive/Datasets/stuff/df_2024.csv')\n",
        "\n",
        "data = pl.concat([data_2021, data_2022, data_2023, data_2024], how='vertical_relaxed')\n",
        "\n",
        "# get year\n",
        "data = data.with_columns(\n",
        "    pl.col('game_date').str.strptime(pl.Date, format=\"%Y-%m-%d\").dt.year().alias('year')\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "24WbzsqO8dZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.write_csv('data_2021_2024.csv')\n",
        "files.download('data_2021_2024.csv')"
      ],
      "metadata": {
        "id": "Vu_AB94EEwqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering and Data Cleaning"
      ],
      "metadata": {
        "id": "o1YJUL7mR5uM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_2021_2024_features = pl.read_csv('/content/drive/MyDrive/Datasets/stuff/data_2021_2024.csv')"
      ],
      "metadata": {
        "id": "ITiQ_3VNR7CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter weird pitches\n",
        "data_2021_2024_features = data_2021_2024_features.filter(~pl.col('pitch_type').is_in(['CS', 'PO', 'EP', 'KN', 'FA',]))\n",
        "# Filter weird events\n",
        "data_2021_2024_features = data_2021_2024_features.filter(\n",
        "    ((~pl.col('events').is_in(['catcher_interf', 'sac_bunt', 'sac_bunt_double_play', 'truncated_pa'])) |\n",
        "     (pl.col('events').is_null())\n",
        "    ) &\n",
        "    ((~pl.col('description').is_in(['missed_bunt', 'foul_bunt', 'bunt_foul_tip'])) |\n",
        "     (pl.col('description').is_null())\n",
        "    )\n",
        ")\n",
        "\n",
        "# Create event targets\n",
        "data_2021_2024_features = data_2021_2024_features.with_columns(\n",
        "    pl.when(pl.col('p_throws') == 'R')\n",
        "    .then(1)\n",
        "    .otherwise(0).alias('righty'),\n",
        "\n",
        "    pl.when(pl.col('description') == 'foul')\n",
        "    .then(pl.col('description'))\n",
        "    .otherwise(pl.col('bb_type')).alias('bb_type'),\n",
        "\n",
        "    swing =\n",
        "    pl.when(\n",
        "        pl.col('description').is_in(['blocked_ball', 'ball', 'hit_by_pitch', 'called_strike'])\n",
        "    )\n",
        "    .then(0)\n",
        "    .otherwise(1),\n",
        "\n",
        "    called_strike =\n",
        "    pl.when(\n",
        "        pl.col('description').is_in(['called_strike'])\n",
        "    )\n",
        "    .then(1)\n",
        "    .otherwise(0),\n",
        "\n",
        "    called_ball =\n",
        "    pl.when(\n",
        "        pl.col('description').is_in(['blocked_ball', 'ball'])\n",
        "    )\n",
        "    .then(1)\n",
        "    .otherwise(0),\n",
        "\n",
        "    called_hbp =\n",
        "    pl.when(\n",
        "        pl.col('description').is_in(['hit_by_pitch'])\n",
        "    )\n",
        "    .then(1)\n",
        "    .otherwise(0),\n",
        "\n",
        "    whiff =\n",
        "    pl.when(\n",
        "        pl.col('description').is_in(['swinging_strike', 'swinging_strike_blocked'])\n",
        "    )\n",
        "    .then(1)\n",
        "    .otherwise(0),\n",
        "\n",
        "    contact =\n",
        "    pl.when(\n",
        "        pl.col('description').is_in(['foul', 'hit_into_play'])\n",
        "    )\n",
        "    .then(1)\n",
        "    .otherwise(0),\n",
        "\n",
        "    foul =\n",
        "    pl.when(\n",
        "        pl.col('description').is_in(['foul'])\n",
        "    )\n",
        "    .then(1)\n",
        "    .otherwise(0),\n",
        "\n",
        "    out =\n",
        "    pl.when(\n",
        "        pl.col('events').is_in(['sac_fly', 'sac_fly_double_play', 'field_error', 'force_out', 'field_out',\n",
        "                                'fielders_choice_out', 'double_play', 'fielders_choice', 'triple_play',\n",
        "                                'strikeout_double_play', 'grounded_into_double_play'])\n",
        "    )\n",
        "    .then(1)\n",
        "    .otherwise(0),\n",
        "\n",
        "    single = pl.when(pl.col('events') == 'single').then(1).otherwise(0),\n",
        "\n",
        "    double = pl.when(pl.col('events') == 'double').then(1).otherwise(0),\n",
        "\n",
        "    triple = pl.when(pl.col('events') == 'triple').then(1).otherwise(0),\n",
        "\n",
        "    home_run = pl.when(pl.col('events') == 'home_run').then(1).otherwise(0),\n",
        "\n",
        "    ground_ball = pl.when(pl.col('bb_type') == 'ground_ball').then(1).otherwise(0),\n",
        "\n",
        "    line_drive = pl.when(pl.col('bb_type') == 'line_drive').then(1).otherwise(0),\n",
        "\n",
        "    fly_ball = pl.when(pl.col('bb_type') == 'fly_ball').then(1).otherwise(0),\n",
        "\n",
        "    popup = pl.when(pl.col('bb_type') == 'popup').then(1).otherwise(0)\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "VGNkUoaJmFR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adjust lefties horz\n",
        "data_2021_2024_features = data_2021_2024_features.with_columns(\n",
        "    pl.when(pl.col('p_throws') == 'L')\n",
        "    .then(pl.col('release_pos_x')*-1)\n",
        "    .otherwise('release_pos_x')\n",
        "    .alias('adj_release_pos_x'),\n",
        "\n",
        "    pl.when(pl.col('p_throws') == 'L')\n",
        "    .then(pl.col('pfx_x')*-1)\n",
        "    .otherwise('pfx_x')\n",
        "    .alias('adj_pfx_x'),\n",
        "\n",
        "    pl.when(pl.col('p_throws')=='L')\n",
        "    .then(360 - pl.col('spin_axis'))\n",
        "    .otherwise(pl.col('spin_axis'))\n",
        "    .alias('adj_spin_axis'),\n",
        "\n",
        "    pl.when(pl.col('p_throws')=='L')\n",
        "    .then(pl.col('vx0')*-1)\n",
        "    .otherwise(pl.col('vx0'))\n",
        "    .alias('adj_vx0'),\n",
        "\n",
        "    pl.when(pl.col('p_throws')=='L')\n",
        "    .then(pl.col('ax')*-1)\n",
        "    .otherwise(pl.col('ax'))\n",
        "    .alias('adj_ax')\n",
        ")\n",
        "\n",
        "# get most thrown fastball\n",
        "pitch_count = (\n",
        "    data_2021_2024_features\n",
        "    .filter(pl.col('pitch_type').is_in(['FF', 'SI', 'FC']))\n",
        "    .select('pitch_type', 'pitcher')\n",
        "    .group_by('pitcher')\n",
        "    .agg(\n",
        "        pl.col('pitch_type')\n",
        "        .mode()\n",
        "        .first()\n",
        "        .alias('primary_fastball')\n",
        "    )\n",
        ")\n",
        "data_2021_2024_features = data_2021_2024_features.join(pitch_count, on='pitcher', how='left')\n",
        "\n",
        "# get avg velo of most thrown fastball\n",
        "fb_velo = (\n",
        "    data_2021_2024_features\n",
        "    .filter(pl.col('pitch_type') == pl.col('primary_fastball'))\n",
        "    .select('pitcher', 'release_speed')\n",
        "    .group_by('pitcher')\n",
        "    .agg(\n",
        "        pl.col('release_speed')\n",
        "        .mean()\n",
        "        .alias('primary_fb_speed')\n",
        "    )\n",
        ")\n",
        "data_2021_2024_features = data_2021_2024_features.join(fb_velo, on='pitcher', how='left')\n",
        "\n",
        "# get avg vert of most thrown fastball\n",
        "fb_vert = (\n",
        "    data_2021_2024_features\n",
        "    .filter(pl.col('pitch_type') == pl.col('primary_fastball'))\n",
        "    .select('pitcher', 'pfx_z')\n",
        "    .group_by('pitcher')\n",
        "    .agg(\n",
        "        pl.col('pfx_z')\n",
        "        .mean()\n",
        "        .alias('primary_fb_vert')\n",
        "    )\n",
        ")\n",
        "data_2021_2024_features = data_2021_2024_features.join(fb_vert, on='pitcher', how='left')\n",
        "\n",
        "# get avg horz of most thrown fastball\n",
        "fb_horz = (\n",
        "    data_2021_2024_features\n",
        "    .filter(pl.col('pitch_type') == pl.col('primary_fastball'))\n",
        "    .select('pitcher', 'pfx_x')\n",
        "    .group_by('pitcher')\n",
        "    .agg(\n",
        "        pl.col('pfx_x')\n",
        "        .mean()\n",
        "        .alias('primary_fb_horz')\n",
        "    )\n",
        ")\n",
        "data_2021_2024_features = data_2021_2024_features.join(fb_horz, on='pitcher', how='left')\n",
        "\n",
        "# get secondary pitch differences\n",
        "data_2021_2024_features = data_2021_2024_features.with_columns(\n",
        "    secondary_velo_differential = pl.when(pl.col('pitch_type').is_in(['FF', 'FC', 'SI']))\n",
        "    .then(0)\n",
        "    .otherwise(pl.col('primary_fb_speed') - pl.col('release_speed')),\n",
        "\n",
        "    secondary_vert_differential = pl.when(pl.col('pitch_type').is_in(['FF', 'FC', 'SI']))\n",
        "    .then(0)\n",
        "    .otherwise(pl.col('primary_fb_vert') - pl.col('pfx_z')),\n",
        "\n",
        "    secondary_horz_differential = pl.when(pl.col('pitch_type').is_in(['FF', 'FC', 'SI']))\n",
        "    .then(0)\n",
        "    .otherwise(pl.col('primary_fb_horz') - pl.col('pfx_x'))\n",
        ")\n",
        "\n",
        "# get same side\n",
        "data_2021_2024_features = data_2021_2024_features.with_columns(\n",
        "    pl.when(pl.col('p_throws')==pl.col('stand'))\n",
        "    .then(1)\n",
        "    .otherwise(0)\n",
        "    .alias('same_side')\n",
        ")"
      ],
      "metadata": {
        "id": "y1BoM-QpUZWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropping Nulls"
      ],
      "metadata": {
        "id": "qSyjislKYMeb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# relevant feats\n",
        "data_2021_2024_features = df.select('game_year', 'game_date', 'player_name', 'batter', 'pitcher',\n",
        "               'pitch_type', 'events', 'description', 'bb_type', 'stand', 'p_throws', 'same_side', 'balls', 'strikes',\n",
        "               'release_pos_x', 'adj_release_pos_x', 'release_pos_z', 'release_pos_y', 'release_extension', 'arm_angle',\n",
        "               'release_speed', 'release_spin_rate', 'spin_axis', 'adj_spin_axis', 'pfx_x', 'adj_pfx_x', 'pfx_z', 'api_break_z_with_gravity', 'api_break_x_arm',\n",
        "               'primary_fb_speed', 'primary_fb_vert', 'primary_fb_horz', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential',\n",
        "               'plate_x', 'plate_z', 'sz_top', 'sz_bot',\n",
        "               'vx0', 'adj_vx0', 'vy0', 'vz0', 'ax', 'adj_ax', 'ay', 'az',\n",
        "               'launch_speed', 'launch_angle', 'estimated_woba_using_speedangle', 'woba_value', 'delta_run_exp', 'delta_home_win_exp')\n",
        "\n",
        "# drop nulls\n",
        "data_2021_2024_features = data_2021_2024_features.drop_nulls(\n",
        "    subset = ['pitch_type', 'release_pos_x', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'api_break_z_with_gravity', 'primary_fb_speed', 'delta_run_exp']\n",
        ")\n",
        "\n",
        "# filter incomplete exit velo/launch angle data\n",
        "data_2021_2024_features = data_2021_2024_features.filter(\n",
        "    ((pl.col('description') != 'hit_into_play')) |\n",
        "    ((pl.col('description') == 'hit_into_play') &\n",
        "        (\n",
        "        (pl.col(\"launch_speed\").is_not_null()) &\n",
        "        (pl.col(\"launch_angle\").is_not_null()) &\n",
        "        (pl.col('bb_type').is_not_null())\n",
        "        )\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "Nc75ZcV6MLQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2021_2024_features.null_count()"
      ],
      "metadata": {
        "id": "6VECcrxoUUQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2021_2024_features.shape"
      ],
      "metadata": {
        "id": "1onX8_TdTlTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2021_2024_features.write_csv('data_2021_2024_features.csv')\n",
        "files.download('data_2021_2024_features.csv')"
      ],
      "metadata": {
        "id": "hL7qs9wLLP1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For model correlation validation"
      ],
      "metadata": {
        "id": "OhM6DQpYDtmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# query relevant performance metrics\n",
        "corr_df = pl.DataFrame(pybaseball.pitching_stats(start_season = 2021, end_season = 2024, qual = 100)).select('Season', 'Name', 'IDfg', 'IP', 'ERA', 'FIP', 'xFIP', 'SIERA', 'botStf', 'Stuff+')\n",
        "\n",
        "# match name format to statcast for joining\n",
        "corr_df = corr_df.with_columns(\n",
        "        pl.col('Name').str.split(\" \").map_elements(lambda parts: f\"{parts[-1]}, {' '.join(parts[:-1])}\").alias('names')\n",
        "        )\n",
        "\n",
        "# next season performance\n",
        "corr_df1 = corr_df.select([\n",
        "    pl.col(\"Name\"),\n",
        "    (pl.col('Season') - 1).alias('Season'),\n",
        "    pl.col(\"ERA\").alias(\"ERA_next\"),\n",
        "    pl.col(\"FIP\").alias(\"FIP_next\"),\n",
        "    pl.col(\"xFIP\").alias(\"xFIP_next\"),\n",
        "    pl.col(\"SIERA\").alias(\"SIERA_next\"),\n",
        "])\n",
        "\n",
        "# joining next season to this season\n",
        "corr_df = corr_df.join(corr_df1, on=['Name', 'Season'], how= 'left')\n",
        "corr_df = corr_df.drop_nulls()"
      ],
      "metadata": {
        "id": "ZQJede33B_1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_df.write_csv('corr_df.csv')\n",
        "files.download('corr_df.csv')"
      ],
      "metadata": {
        "id": "6Mt99iX4CJZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Models (XGBoost)"
      ],
      "metadata": {
        "id": "yXzQVeMwLG0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pl.read_csv('/content/drive/MyDrive/Datasets/stuff/data_2021_2024_features.csv')"
      ],
      "metadata": {
        "id": "qyPowKE9nOdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "LJtL1AOVEmSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validation_plot(df, actuals, preds, model_name):\n",
        "    r2 = (r2_score(df.select(actuals), df.select(preds)))\n",
        "    rmse = np.sqrt(mean_squared_error(df.select(actuals), df.select(preds)))\n",
        "\n",
        "    sns.regplot(data=df, x = preds, y = actuals)\n",
        "    plt.xlabel('Preds')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title(f'{model_name} Validation \\nRMSE: {round(rmse, 4)}, R-Squared: {round(r2, 4)}')\n",
        "    plt.xlim([-3, 4])\n",
        "    plt.ylim([-3, 4])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "fjXSNeLYlmkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_df = pl.read_csv('/content/drive/MyDrive/Datasets/stuff/corr_df.csv')\n",
        "def corr_valid(df = df, metric = None, model = \"\"):\n",
        "    corr_df1 = corr_df.clone()\n",
        "    # get mean stuff in year\n",
        "    mean_stuff = df.group_by(pl.col('game_year'), pl.col('player_name')).agg(pl.col(metric).mean())\n",
        "    # join to performance corr df\n",
        "    corr_df1 = corr_df1.join(mean_stuff, left_on = ['Season', 'names'], right_on = ['game_year', 'player_name'], how='inner')\n",
        "    y_vars = ['ERA_next', 'FIP_next', 'xFIP_next', 'SIERA_next']\n",
        "    x_vars = ['ERA', 'FIP', 'xFIP', 'SIERA', 'botStf', 'Stuff+', metric]\n",
        "\n",
        "    correlations = []\n",
        "\n",
        "    # get correlations for each metric\n",
        "    for x in x_vars:\n",
        "        row = []\n",
        "        for y in y_vars:\n",
        "            corr = corr_df1.select(pl.corr(x, y)).item()\n",
        "            row.append(abs(corr))\n",
        "        correlations.append(row)\n",
        "\n",
        "    # corr df for heatmap\n",
        "    corr_pd = pd.DataFrame((correlations), index=x_vars, columns=y_vars)\n",
        "\n",
        "    # plot heatmap\n",
        "    sns.heatmap(corr_pd, annot=True, vmin = 0.2, vmax = 0.65, cmap=\"coolwarm\", fmt = '.2f')\n",
        "    plt.title(f\"{model} Correlation Matrix (Min 100 IP)\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "gFl_5ufhBqIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CatBoost"
      ],
      "metadata": {
        "id": "3bJdwwihMP_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# catboost model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'delta_run_exp'\n",
        "\n",
        "df_pandas = df.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "model = CatBoostRegressor(\n",
        "    cat_features = ['righty'],\n",
        "    loss_function = 'RMSE'\n",
        ")\n",
        "preds = cross_val_predict(model, X, y , cv=5, method='predict')\n",
        "\n",
        "df = df.with_columns(pl.Series(\"run_exp_pred_catboost\", preds))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3IqC0sscmf1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_plot(df = df, actuals = 'delta_run_exp', preds = 'run_exp_pred_catboost', model_name = 'CatBoost')"
      ],
      "metadata": {
        "id": "qjxJKtDIvzr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_valid(metric = 'run_exp_pred_catboost', model = 'CatBoost')"
      ],
      "metadata": {
        "id": "e8kzIdcTBVl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "yekgXlchMUIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost model\n",
        "df = df.with_columns(\n",
        "    righty = pl.when(pl.col('p_throws') == 'R')\n",
        "    .then(1)\n",
        "    .otherwise(0)\n",
        ")\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'delta_run_exp'\n",
        "\n",
        "df_pandas = df.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "model = XGBRegressor()\n",
        "preds = cross_val_predict(model, X, y , cv=5, method='predict')\n",
        "\n",
        "df = df.with_columns(pl.Series(\"run_exp_pred_xgb\", preds))"
      ],
      "metadata": {
        "id": "bAvDc_IwI9jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_plot(df = df, actuals = 'delta_run_exp', preds = 'run_exp_pred_xgb', model_name = 'XGBoost')"
      ],
      "metadata": {
        "id": "CaVX2Q-6JAR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_valid(metric = 'run_exp_pred_xgb', model = 'XGBoost')"
      ],
      "metadata": {
        "id": "h681IiG0JB8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rv pred distribution\n",
        "sns.histplot(df.select(pl.col('run_exp_pred_xgb')))\n",
        "plt.xlim([-0.05, 0.05])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IlCfZovic_uF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best stuff by year\n",
        "df.group_by(pl.col('game_year'), pl.col('player_name')).agg(pl.col('run_exp_pred_xgb').mean()).sort('run_exp_pred_xgb', descending = False).head(10)"
      ],
      "metadata": {
        "id": "HFnGxO55LrKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best pitches by year\n",
        "(df.with_columns([\n",
        "        pl.len().over([\"player_name\", \"pitch_type\"]).alias(\"pitch_count\")\n",
        "    ])\n",
        "    .filter(pl.col(\"pitch_count\") >= 100)\n",
        "    .group_by(pl.col('game_year'), pl.col('player_name'), pl.col('pitch_type'))\n",
        "    .agg(pl.col('run_exp_pred_xgb').mean())\n",
        "    .sort('run_exp_pred_xgb', descending = False).head(10)\n",
        ")"
      ],
      "metadata": {
        "id": "Jbu1okvakFic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.write_csv('df1.csv')\n",
        "files.download('df1.csv')"
      ],
      "metadata": {
        "id": "8OmKewbMsp50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LGBM"
      ],
      "metadata": {
        "id": "l73U37vYMYZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lgbm model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'delta_run_exp'\n",
        "\n",
        "df_pandas = df.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "model = LGBMRegressor()\n",
        "preds = cross_val_predict(model, X, y , cv=5, method='predict')\n",
        "\n",
        "df = df.with_columns(pl.Series(\"run_exp_pred_lgbm\", preds))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "o6gCaC2Ca10u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_plot(df = df, actuals = 'delta_run_exp', preds = 'run_exp_pred_lgbm', model_name = 'LGBM')"
      ],
      "metadata": {
        "id": "wUihFBPtbbHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_valid(metric = 'run_exp_pred_lgbm', model = 'LGBM')"
      ],
      "metadata": {
        "id": "hF4bbM6AePAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Net 2 Hidden Layers"
      ],
      "metadata": {
        "id": "SfS5cQLBMbTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural net 3 layers\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'delta_run_exp'\n",
        "\n",
        "df_pandas = df.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "y_pred_all = np.zeros_like(y)\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    model = Sequential([\n",
        "        Dense(64, activation = 'relu', input_shape = (X.shape[1], )),\n",
        "        Dense(32, activation = 'relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer = Adam(), loss = 'mse')\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor = 'val_loss',\n",
        "        patience = 0,\n",
        "        restore_best_weights = True,\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train, validation_split = 0.2, batch_size = 1024, epochs = 15, callbacks = [early_stop], verbose = 1)\n",
        "\n",
        "    y_pred = model.predict(X_test_scaled).flatten()\n",
        "\n",
        "    y_pred_all[test_idx] = y_pred\n",
        "\n",
        "df = df.with_columns(pl.Series(\"run_exp_pred_nn\", y_pred_all))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5syKQ8_7zBFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_plot(df = df, actuals = 'delta_run_exp', preds = 'run_exp_pred_nn', model_name = 'Neural Net 3 Layers')"
      ],
      "metadata": {
        "id": "m1SErOaFsJjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_valid(metric = 'run_exp_pred_nn', model = 'Neural Net 3 Layers')"
      ],
      "metadata": {
        "id": "9Y2MxQbTubSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Net 3 Hidden Layers"
      ],
      "metadata": {
        "id": "SM4GMWnPMd5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural net 4 layers\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'delta_run_exp'\n",
        "\n",
        "df_pandas = df.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "y_pred_all = np.zeros_like(y)\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    model = Sequential([\n",
        "        Dense(128, activation = 'relu', input_shape = (X.shape[1], )),\n",
        "        Dense(64, activation = 'relu'),\n",
        "        Dense(32, activation = 'relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer = Adam(learning_rate = 0.0005), loss = 'mse')\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor = 'val_loss',\n",
        "        patience = 2,\n",
        "        restore_best_weights = True,\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train, validation_split = 0.2, batch_size = 1024, epochs = 15, callbacks = [early_stop], verbose = 1)\n",
        "\n",
        "    y_pred = model.predict(X_test_scaled).flatten()\n",
        "\n",
        "    y_pred_all[test_idx] = y_pred\n",
        "\n",
        "df = df.with_columns(pl.Series(\"run_exp_pred_nn_4\", y_pred_all))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kuFVg9nFURya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_plot(df = df, actuals = 'delta_run_exp', preds = 'run_exp_pred_nn_4', model_name = 'Neural Net 4 Layers')"
      ],
      "metadata": {
        "id": "0ertlT1ZUneX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_valid(metric = 'run_exp_pred_nn_4', model = 'Neural Net 4 Layers')"
      ],
      "metadata": {
        "id": "G4Ugla5vipHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Swing Model (XGBoost)"
      ],
      "metadata": {
        "id": "N5L-I4VesBBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calibration_plot(data = None, n_bins = 10, preds = None, actuals = None, model = None):\n",
        "    fig, (ax1,ax2) = plt.subplots(1,2, figsize=(12,4))\n",
        "\n",
        "    sns.histplot(data[preds], ax = ax1)\n",
        "    ax1.set_xlabel('Predicted Probability')\n",
        "    ax1.set_ylabel('Count')\n",
        "    ax1.set_title(f'{model} \\nPredicted Probability Distribution')\n",
        "    ax1.set_xlim([0, 1])\n",
        "\n",
        "    # Bin predicted probabilities\n",
        "    _df = data.with_columns([\n",
        "        (pl.col(preds) * 10)\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"bin\")\n",
        "    ])\n",
        "    _df = _df.with_columns(\n",
        "        bin = pl.when(pl.col('bin') > 9)\n",
        "        .then(9)\n",
        "        .otherwise(pl.col('bin'))\n",
        "    )\n",
        "\n",
        "    logloss = round(log_loss(_df[actuals], _df[preds]), 4)\n",
        "\n",
        "    # Group by bin and calculate avg predicted prob and actual rate\n",
        "    binned = (\n",
        "        _df.group_by(\"bin\")\n",
        "        .agg([\n",
        "            pl.col(preds).mean().alias(\"mean_pred_prob\"),\n",
        "            pl.col(actuals).mean().alias(\"empirical_prob\"),\n",
        "            pl.len().alias(\"count\")\n",
        "        ])\n",
        "        .sort(\"bin\")\n",
        "    )\n",
        "\n",
        "    binned_pd = binned.to_pandas()\n",
        "\n",
        "    # Plot calibration curve\n",
        "    ax2.plot(binned_pd[\"mean_pred_prob\"], binned_pd[\"empirical_prob\"], marker='o', label='Calibration')\n",
        "    ax2.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfect Calibration')\n",
        "    ax2.set_xlabel('Mean Predicted Probability')\n",
        "    ax2.set_ylabel('Empirical Probability')\n",
        "    ax2.set_title(f'{model} Calibration Plot \\nLog Loss: {logloss}')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "AgImTCOrmMod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['swing'].mean()"
      ],
      "metadata": {
        "id": "L8azbP_lNspf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "z4XdDlUcLeqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'swing'\n",
        "\n",
        "df_pandas = df.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "model = XGBClassifier()\n",
        "preds = cross_val_predict(model, X, y , cv=5, method='predict_proba')\n",
        "\n",
        "df = df.with_columns(pl.Series(\"swing_pred_xgb\", preds[:, 1]),\n",
        "                     pl.Series(\"take_pred_xgb\", preds[:, 0]))"
      ],
      "metadata": {
        "id": "OB91xwqY1v-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(n_bins = 10, data = df, preds = 'swing_pred_xgb', actuals = 'swing', model = 'XGBoost Swing')"
      ],
      "metadata": {
        "id": "leKnvjvfIQVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Net 2 Layers"
      ],
      "metadata": {
        "id": "_9Yzd4xbxr6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural net 2 layers\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'swing'\n",
        "\n",
        "df_pandas = df.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "y_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape = (X.shape[1], )),\n",
        "        Dense(32, activation = 'relu'),\n",
        "        Dense(1, activation = 'sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer = Adam(), loss = 'binary_crossentropy')\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor = 'val_loss',\n",
        "        patience = 0,\n",
        "        restore_best_weights = True,\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train, validation_split = 0.2, batch_size = 1024, epochs = 15, callbacks = [early_stop], verbose = 1)\n",
        "\n",
        "    y_pred = model.predict(X_test_scaled).flatten()\n",
        "\n",
        "    y_pred_all[test_idx] = y_pred\n",
        "\n",
        "df = df.with_columns(pl.Series(\"swing_pred_nn\", y_pred_all))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6Nj-MbiGtUNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df, n_bins = 10, preds = 'swing_pred_nn', actuals = 'swing', model = 'Neural Net 2 Layers Swing')"
      ],
      "metadata": {
        "id": "R7zVtpfatdFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Strike/Ball/HBP Model (3 Layer DNN)"
      ],
      "metadata": {
        "id": "AuqAjTW7WKuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filter to relevant rows\n",
        "df_take = df.filter(pl.col('swing') == 0)\n",
        "\n",
        "df_take = df_take.with_columns([\n",
        "    pl.when(pl.col('called_strike') == 1)\n",
        "    .then(0)\n",
        "    .when(pl.col('called_ball') ==  1)\n",
        "    .then(1)\n",
        "    .otherwise(2)\n",
        "    .alias('take_target')\n",
        "])"
      ],
      "metadata": {
        "id": "8WDWjzLyNdaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_take['called_strike'].mean()"
      ],
      "metadata": {
        "id": "-NsBc4N9-FMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_take['called_ball'].mean()"
      ],
      "metadata": {
        "id": "JXFQIOma-Jh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "z4AvIc69M7YZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'take_target'\n",
        "\n",
        "df_pandas = df_take.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "model = XGBClassifier(objective = 'multi:softprob', num_class = 3, eval_metric = 'mlogloss')\n",
        "preds = cross_val_predict(model, X, y , cv=5, method='predict_proba')\n",
        "\n",
        "df_take = df_take.with_columns(pl.Series(\"called_strike_pred_xgb\", preds[:, 0]),\n",
        "                               pl.Series(\"called_ball_pred_xgb\", preds[:, 1]),\n",
        "                               pl.Series(\"called_hbp_pred_xgb\", preds[:, 2]))"
      ],
      "metadata": {
        "id": "Kizg1B5CWiBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_take, preds = 'called_strike_pred_xgb', actuals = 'called_strike', model = 'XGBoost Called Model (Strikes)')"
      ],
      "metadata": {
        "id": "XuPary0vbf7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_take, preds = 'called_ball_pred_xgb', actuals = 'called_ball', model = 'XGBoost Called Model (Balls)')"
      ],
      "metadata": {
        "id": "BxYNjRdEbsJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_take, preds = 'called_hbp_pred_xgb', actuals = 'called_hbp', model = 'XGBoost Called Model (HBPs)')"
      ],
      "metadata": {
        "id": "C2eb7Xigb3Ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost Isotonic"
      ],
      "metadata": {
        "id": "7N7u4_nTM9U4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost isotonic model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'take_target'\n",
        "\n",
        "df_pandas = df_take.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "strike_pred_all = np.zeros_like(y, dtype=float)\n",
        "ball_pred_all = np.zeros_like(y, dtype=float)\n",
        "hbp_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    xgb = XGBClassifier(objective = 'multi:softprob', num_class = 3, eval_metric = 'mlogloss')\n",
        "\n",
        "    calibrated_xgb = CalibratedClassifierCV(xgb, method = 'isotonic', cv = 3)\n",
        "    calibrated_xgb.fit(X_train, y_train)\n",
        "\n",
        "    preds = calibrated_xgb.predict_proba(X_test)\n",
        "\n",
        "    strike_pred_all[test_idx] = preds[:, 0]\n",
        "    ball_pred_all[test_idx] = preds[:, 1]\n",
        "    hbp_pred_all[test_idx] = preds[:, 2]\n",
        "\n",
        "\n",
        "df_take = df_take.with_columns(pl.Series(\"called_strike_pred_xgb_calibrated\", strike_pred_all),\n",
        "                               pl.Series(\"called_ball_pred_xgb_calibrated\", ball_pred_all),\n",
        "                               pl.Series(\"called_hbp_pred_xgb_calibrated\", hbp_pred_all))"
      ],
      "metadata": {
        "id": "s_bjlRsyb9tD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_take, preds = 'called_strike_pred_xgb_calibrated', actuals = 'called_strike', model = 'XGBoost Called Model Isotonic Calibrated (Strikes)')"
      ],
      "metadata": {
        "id": "yma0r8bgvnwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_take, preds = 'called_ball_pred_xgb_calibrated', actuals = 'called_ball', model = 'XGBoost Called Model Isotonic Calibrated (Balls)')"
      ],
      "metadata": {
        "id": "ohulqT1xzSeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_take, preds = 'called_hbp_pred_xgb_calibrated', actuals = 'called_hbp', model = 'XGBoost Called Model Calibrated (HBP)')"
      ],
      "metadata": {
        "id": "-FxdN5sAzbGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Net 4 Layers"
      ],
      "metadata": {
        "id": "t9rkp4QvM_J3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural net 4 layer model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'take_target'\n",
        "\n",
        "df_pandas = df_take.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "strike_pred_all = np.zeros_like(y, dtype=float)\n",
        "ball_pred_all = np.zeros_like(y, dtype=float)\n",
        "hbp_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    model = Sequential([\n",
        "        Dense(128, activation = 'relu', input_shape = (X.shape[1],)),\n",
        "        Dense(64, activation = 'relu'),\n",
        "        Dense(32, activation = 'relu'),\n",
        "        Dense(3, activation = 'softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor = 'val_loss',\n",
        "        patience = 0,\n",
        "        restore_best_weights = True,\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train, validation_split = 0.2, callbacks = [early_stop], epochs = 15, batch_size = 1024, verbose = 1)\n",
        "\n",
        "    preds = model.predict(X_test_scaled)\n",
        "\n",
        "    strike_pred_all[test_idx] = preds[:, 0]\n",
        "    ball_pred_all[test_idx] = preds[:, 1]\n",
        "    hbp_pred_all[test_idx] = preds[:, 2]\n",
        "\n",
        "\n",
        "df_take = df_take.with_columns(pl.Series(\"called_strike_pred_nn\", strike_pred_all),\n",
        "                               pl.Series(\"called_ball_pred_nn\", ball_pred_all),\n",
        "                               pl.Series(\"called_hbp_pred_nn\", hbp_pred_all))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "0actuZYxzsYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_take, preds = 'called_strike_pred_nn', actuals = 'called_strike', model = 'Neural Net 4 Layers Called Model (Strikes)')"
      ],
      "metadata": {
        "id": "Ibjl9JCk1tr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_take, preds = 'called_ball_pred_nn', actuals = 'called_ball', model = 'Neural Net 4 Layers Called Model (Balls)')"
      ],
      "metadata": {
        "id": "-wHfIDuk34-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_take, preds = 'called_hbp_pred_nn', actuals = 'called_hbp', model = 'Neural Net 4 Layers Called Model (HBPs)')"
      ],
      "metadata": {
        "id": "1Qlg5OsH4Aoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Net 3 Layers"
      ],
      "metadata": {
        "id": "wdK1Jj_iNEk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural net 3 dense layer model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'take_target'\n",
        "\n",
        "df_pandas = df_take.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "strike_pred_all = np.zeros_like(y, dtype=float)\n",
        "ball_pred_all = np.zeros_like(y, dtype=float)\n",
        "hbp_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape = (X.shape[1],)),\n",
        "        Dense(64, activation = 'relu'),\n",
        "        Dense(32, activation = 'relu'),\n",
        "        Dense(3, activation = 'softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor = 'val_loss',\n",
        "        patience = 0,\n",
        "        restore_best_weights = True,\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train, validation_split = 0.2, callbacks = [early_stop], epochs = 15, batch_size = 1024, verbose = 1)\n",
        "\n",
        "    preds = model.predict(X_test_scaled)\n",
        "\n",
        "    strike_pred_all[test_idx] = preds[:, 0]\n",
        "    ball_pred_all[test_idx] = preds[:, 1]\n",
        "    hbp_pred_all[test_idx] = preds[:, 2]\n",
        "\n",
        "\n",
        "df_take = df_take.with_columns(pl.Series(\"called_strike_pred_nn\", strike_pred_all),\n",
        "                               pl.Series(\"called_ball_pred_nn\", ball_pred_all),\n",
        "                               pl.Series(\"called_hbp_pred_nn\", hbp_pred_all))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SuKknGvD4Fn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_take, preds = 'called_strike_pred_nn', actuals = 'called_strike', model = 'Neural Net 3 Layers Called Model (Strikes)')"
      ],
      "metadata": {
        "id": "lTzWyb8W-5qT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_take, preds = 'called_ball_pred_nn', actuals = 'called_ball', model = 'Neural Net 3 Layers Called Model (Balls)')"
      ],
      "metadata": {
        "id": "J7KnwYHpAaJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_take, preds = 'called_hbp_pred_nn', actuals = 'called_hbp', model = 'Neural Net 3 Layers Called Model (HBPs)')"
      ],
      "metadata": {
        "id": "UvyGMs_YAepi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Net 2 Layers"
      ],
      "metadata": {
        "id": "70xCikWMNIMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural net 2 dense layer model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'take_target'\n",
        "\n",
        "df_pandas = df_take.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "strike_pred_all = np.zeros_like(y, dtype=float)\n",
        "ball_pred_all = np.zeros_like(y, dtype=float)\n",
        "hbp_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape = (X.shape[1],)),\n",
        "        Dense(32, activation = 'relu'),\n",
        "        Dense(3, activation = 'softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor = 'val_loss',\n",
        "        patience = 0,\n",
        "        restore_best_weights = True,\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train, validation_split = 0.2, callbacks = [early_stop], epochs = 15, batch_size = 1024, verbose = 1)\n",
        "\n",
        "    preds = model.predict(X_test_scaled)\n",
        "\n",
        "    strike_pred_all[test_idx] = preds[:, 0]\n",
        "    ball_pred_all[test_idx] = preds[:, 1]\n",
        "    hbp_pred_all[test_idx] = preds[:, 2]\n",
        "\n",
        "\n",
        "df_take = df_take.with_columns(pl.Series(\"called_strike_pred_nn\", strike_pred_all),\n",
        "                               pl.Series(\"called_ball_pred_nn\", ball_pred_all),\n",
        "                               pl.Series(\"called_hbp_pred_nn\", hbp_pred_all))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3WQTP-UvAg7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_take, preds = 'called_strike_pred_nn', actuals = 'called_strike', model = 'Neural Net 2 Layers Called Model (Strikes)')"
      ],
      "metadata": {
        "id": "z-XoxsuuA2ZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_take, preds = 'called_ball_pred_nn', actuals = 'called_ball', model = 'Neural Net 2 Layers Called Model (Balls)')"
      ],
      "metadata": {
        "id": "xIU9DUm5CoYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_take, preds = 'called_hbp_pred_nn', actuals = 'called_hbp', model = 'Neural Net 2 Layers Called Model (HBPs)')"
      ],
      "metadata": {
        "id": "osP7elHOCupW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contact/Whiff Model (XGBoost Sigmoid)"
      ],
      "metadata": {
        "id": "fsMF4lbAImMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filter to relevant rows\n",
        "df_contact = df.filter(pl.col('swing') == 1)"
      ],
      "metadata": {
        "id": "SBG_TsDXIvK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_contact['contact'].mean()"
      ],
      "metadata": {
        "id": "LjK3AGJmJzRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "NKcDRmDjNaTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'contact'\n",
        "\n",
        "df_pandas = df_contact.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "model = XGBClassifier()\n",
        "preds = cross_val_predict(model, X, y , cv=5, method='predict_proba')\n",
        "\n",
        "df_contact = df_contact.with_columns(pl.Series(\"whiff_pred_xgb\", preds[:, 0]),\n",
        "                               pl.Series(\"contact_pred_xgb\", preds[:, 1]))"
      ],
      "metadata": {
        "id": "1GwlZmS8JzRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_contact, preds = 'contact_pred_xgb', actuals = 'contact', model = 'XGBoost Contact Model')"
      ],
      "metadata": {
        "id": "lCX8iwZkQM_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGboost Isotonic"
      ],
      "metadata": {
        "id": "U-nYyJ-MNdS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost isotonic model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'contact'\n",
        "\n",
        "df_pandas = df_contact.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "contact_pred_all = np.zeros_like(y, dtype=float)\n",
        "whiff_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    xgb = XGBClassifier()\n",
        "\n",
        "    calibrated_xgb = CalibratedClassifierCV(xgb, method = 'isotonic', cv = 3)\n",
        "    calibrated_xgb.fit(X_train, y_train)\n",
        "\n",
        "    preds = calibrated_xgb.predict_proba(X_test)\n",
        "\n",
        "    contact_pred_all[test_idx] = preds[:, 1]\n",
        "    whiff_pred_all[test_idx] = preds[:, 0]\n",
        "\n",
        "\n",
        "df_contact = df_contact.with_columns(pl.Series(\"contact_pred_xgb_calibrated\", contact_pred_all),\n",
        "                               pl.Series(\"whiff_pred_xgb_calibrated\", whiff_pred_all))"
      ],
      "metadata": {
        "id": "njtt8f6YQlCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_contact, preds = 'contact_pred_xgb_calibrated', actuals = 'contact', model = 'XGBoost Contact Model Calibrated')"
      ],
      "metadata": {
        "id": "ahkvQ9g4RYRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost Sigmoid"
      ],
      "metadata": {
        "id": "HDPGlUbENgep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost sigmoid model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'contact'\n",
        "\n",
        "df_pandas = df_contact.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "contact_pred_all = np.zeros_like(y, dtype=float)\n",
        "whiff_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    xgb = XGBClassifier()\n",
        "\n",
        "    calibrated_xgb = CalibratedClassifierCV(xgb, method = 'sigmoid', cv = 3)\n",
        "    calibrated_xgb.fit(X_train, y_train)\n",
        "\n",
        "    preds = calibrated_xgb.predict_proba(X_test)\n",
        "\n",
        "    contact_pred_all[test_idx] = preds[:, 1]\n",
        "    whiff_pred_all[test_idx] = preds[:, 0]\n",
        "\n",
        "\n",
        "df_contact = df_contact.with_columns(pl.Series(\"contact_pred_xgb_calibrated\", contact_pred_all),\n",
        "                               pl.Series(\"whiff_pred_xgb_calibrated\", whiff_pred_all))"
      ],
      "metadata": {
        "id": "REiCyBSeGdx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_contact, preds = 'contact_pred_xgb_calibrated', actuals = 'contact', model = 'XGBoost Contact Model Calibrated (Sigmoid)')"
      ],
      "metadata": {
        "id": "SVa4_P0tGgFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Net 4 Layers"
      ],
      "metadata": {
        "id": "AMqjHdP0Nia-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural net 4 layers\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'contact'\n",
        "\n",
        "df_pandas = df_contact.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "y_pred_all = np.zeros_like(y, dtype=float)\n",
        "whiff_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape = (X.shape[1], )),\n",
        "        Dense(128, activation = 'relu'),\n",
        "        Dense(64, activation = 'relu'),\n",
        "        Dense(32, activation = 'relu'),\n",
        "        Dense(1, activation = 'sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer = Adam(), loss = 'binary_crossentropy')\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor = 'val_loss',\n",
        "        patience = 0,\n",
        "        restore_best_weights = True,\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train, validation_split = 0.2, batch_size = 1024, epochs = 15, callbacks = [early_stop], verbose = 1)\n",
        "\n",
        "    y_pred = model.predict(X_test_scaled).flatten()\n",
        "\n",
        "    y_pred_all[test_idx] = y_pred\n",
        "\n",
        "df_contact = df_contact.with_columns(pl.Series(\"contact_pred_nn\", y_pred_all),\n",
        "                                     pl.Series(\"whiff_pred_nn\", 1 - y_pred_all))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "15vmrxdcSE3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_contact, preds = 'contact_pred_nn', actuals = 'contact', model = 'Neural Net 4 Layers Contact Model')"
      ],
      "metadata": {
        "id": "nRnxsag5UKjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Net 3 Layers"
      ],
      "metadata": {
        "id": "kiOuhVCZNkgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural net 3 layers\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'contact'\n",
        "\n",
        "df_pandas = df_contact.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "y_pred_all = np.zeros_like(y, dtype=float)\n",
        "whiff_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape = (X.shape[1], )),\n",
        "        Dense(64, activation = 'relu'),\n",
        "        Dense(32, activation = 'relu'),\n",
        "        Dense(1, activation = 'sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer = Adam(), loss = 'binary_crossentropy')\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor = 'val_loss',\n",
        "        patience = 0,\n",
        "        restore_best_weights = True,\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train, validation_split = 0.2, batch_size = 1024, epochs = 15, callbacks = [early_stop], verbose = 1)\n",
        "\n",
        "    y_pred = model.predict(X_test_scaled).flatten()\n",
        "\n",
        "    y_pred_all[test_idx] = y_pred\n",
        "\n",
        "df_contact = df_contact.with_columns(pl.Series(\"contact_pred_nn\", y_pred_all),\n",
        "                                     pl.Series(\"whiff_pred_nn\", 1 - y_pred_all))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ttNDR4bzWFbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_contact, preds = 'contact_pred_nn', actuals = 'contact', model = 'Neural Net 3 Layers Contact Model')"
      ],
      "metadata": {
        "id": "pRGHdd7fzBaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batted Ball Model (3 Layer DNN)"
      ],
      "metadata": {
        "id": "Ev7JpXAb2IO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filter to relevant rows\n",
        "df_bb = df.filter(pl.col('contact') == 1)\n",
        "\n",
        "# create target col\n",
        "df_bb = df_bb.with_columns(\n",
        "    pl.when(pl.col('bb_type') == 'foul')\n",
        "    .then(0)\n",
        "    .when(pl.col('bb_type') == 'ground_ball')\n",
        "    .then(1)\n",
        "    .when(pl.col('bb_type') == 'line_drive')\n",
        "    .then(2)\n",
        "    .when(pl.col('bb_type') == 'fly_ball')\n",
        "    .then(3)\n",
        "    .when(pl.col('bb_type') == 'popup')\n",
        "    .then(4)\n",
        "    .alias('bb_target')\n",
        ")"
      ],
      "metadata": {
        "id": "v5WZXKn87E1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bb['foul'].mean()"
      ],
      "metadata": {
        "id": "snmNqf0hN2NE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bb['ground_ball'].mean()"
      ],
      "metadata": {
        "id": "48vSv7EhN6fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bb['line_drive'].mean()"
      ],
      "metadata": {
        "id": "IkibR1f3N6YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bb['fly_ball'].mean()"
      ],
      "metadata": {
        "id": "EYwK4XpYN6Qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bb['popup'].mean()"
      ],
      "metadata": {
        "id": "yDEZri9tN6Hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "47zcDXycLUno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'bb_target'\n",
        "\n",
        "df_pandas = df_bb.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "model = XGBClassifier(objective = 'multi:softprob', num_class = 5, eval_metric = 'mlogloss')\n",
        "preds = cross_val_predict(model, X, y , cv=5, method='predict_proba')\n",
        "\n",
        "df_bb = df_bb.with_columns(pl.Series(\"foul_pred_xgb\", preds[:, 0]),\n",
        "                               pl.Series(\"gb_pred_xgb\", preds[:, 1]),\n",
        "                               pl.Series(\"ld_pred_xgb\", preds[:, 2]),\n",
        "                               pl.Series(\"fb_pred_xgb\", preds[:, 3]),\n",
        "                               pl.Series(\"po_pred_xgb\", preds[:, 4]))"
      ],
      "metadata": {
        "id": "GSOGSEDv_H4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'foul_pred_xgb', actuals = 'foul', model = 'XGBoost Batted Ball Model (Foul)')"
      ],
      "metadata": {
        "id": "f2OHChJxH3dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'gb_pred_xgb', actuals = 'ground_ball', model = 'XGBoost Batted Ball Model (Ground Ball)')"
      ],
      "metadata": {
        "id": "mdSnlYRKJKpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'ld_pred_xgb', actuals = 'line_drive', model = 'XGBoost Batted Ball Model (Line Drive)')"
      ],
      "metadata": {
        "id": "8WgKGA8AJKbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'fb_pred_xgb', actuals = 'fly_ball', model = 'XGBoost Batted Ball Model (Fly Ball)')"
      ],
      "metadata": {
        "id": "H66vAf1XJKUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'po_pred_xgb', actuals = 'popup', model = 'XGBoost Batted Ball Model (Popup)')"
      ],
      "metadata": {
        "id": "RG0waCWXJKJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost Isotonic"
      ],
      "metadata": {
        "id": "OPPmQa6ILudV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost isotonic model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'bb_target'\n",
        "\n",
        "df_pandas = df_bb.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "foul_pred_all = np.zeros_like(y, dtype=float)\n",
        "gb_pred_all = np.zeros_like(y, dtype=float)\n",
        "ld_pred_all = np.zeros_like(y, dtype=float)\n",
        "fb_pred_all = np.zeros_like(y, dtype=float)\n",
        "po_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    xgb = XGBClassifier(objective = 'multi:softprob', num_class = 5, eval_metric = 'mlogloss')\n",
        "\n",
        "    calibrated_xgb = CalibratedClassifierCV(xgb, method = 'isotonic', cv = 3)\n",
        "    calibrated_xgb.fit(X_train, y_train)\n",
        "\n",
        "    preds = calibrated_xgb.predict_proba(X_test)\n",
        "\n",
        "    foul_pred_all[test_idx] = preds[:, 0]\n",
        "    gb_pred_all[test_idx] = preds[:, 1]\n",
        "    ld_pred_all[test_idx] = preds[:, 2]\n",
        "    fb_pred_all[test_idx] = preds[:, 3]\n",
        "    po_pred_all[test_idx] = preds[:, 4]\n",
        "\n",
        "df_bb = df_bb.with_columns(pl.Series(\"foul_pred_xgb\", foul_pred_all),\n",
        "                               pl.Series(\"gb_pred_xgb\", gb_pred_all),\n",
        "                               pl.Series(\"ld_pred_xgb\", ld_pred_all),\n",
        "                               pl.Series(\"fb_pred_xgb\", fb_pred_all),\n",
        "                               pl.Series(\"po_pred_xgb\", po_pred_all))"
      ],
      "metadata": {
        "id": "QMQgqnE4LTMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'foul_pred_xgb', actuals = 'foul', model = 'XGBoost Batted Ball Model Calibrated Isotonic (Foul)')"
      ],
      "metadata": {
        "id": "ZeXnsUhUMMHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'gb_pred_xgb', actuals = 'ground_ball', model = 'XGBoost Batted Ball Model Calibrated Isotonic (Ground Ball)')"
      ],
      "metadata": {
        "id": "srXlR84QQvo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'ld_pred_xgb', actuals = 'line_drive', model = 'XGBoost Batted Ball Model Calibrated Isotonic (Line Drive)')"
      ],
      "metadata": {
        "id": "ydEvDVD2Qvjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'fb_pred_xgb', actuals = 'fly_ball', model = 'XGBoost Batted Ball Model Calibrated Isotonic (Fly Ball)')"
      ],
      "metadata": {
        "id": "gMEGeIMBQveO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'po_pred_xgb', actuals = 'popup', model = 'XGBoost Batted Ball Model Calibrated Isotonic (Pop Up)')"
      ],
      "metadata": {
        "id": "S_p2-JNNQvVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost Sigmoid"
      ],
      "metadata": {
        "id": "u2WkQAe2R9H7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost sigmoid model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'bb_target'\n",
        "\n",
        "df_pandas = df_bb.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "foul_pred_all = np.zeros_like(y, dtype=float)\n",
        "gb_pred_all = np.zeros_like(y, dtype=float)\n",
        "ld_pred_all = np.zeros_like(y, dtype=float)\n",
        "fb_pred_all = np.zeros_like(y, dtype=float)\n",
        "po_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    xgb = XGBClassifier(objective = 'multi:softprob', num_class = 5, eval_metric = 'mlogloss')\n",
        "\n",
        "    calibrated_xgb = CalibratedClassifierCV(xgb, method = 'sigmoid', cv = 3)\n",
        "    calibrated_xgb.fit(X_train, y_train)\n",
        "\n",
        "    preds = calibrated_xgb.predict_proba(X_test)\n",
        "\n",
        "    foul_pred_all[test_idx] = preds[:, 0]\n",
        "    gb_pred_all[test_idx] = preds[:, 1]\n",
        "    ld_pred_all[test_idx] = preds[:, 2]\n",
        "    fb_pred_all[test_idx] = preds[:, 3]\n",
        "    po_pred_all[test_idx] = preds[:, 4]\n",
        "\n",
        "df_bb = df_bb.with_columns(pl.Series(\"foul_pred_xgb\", foul_pred_all),\n",
        "                               pl.Series(\"gb_pred_xgb\", gb_pred_all),\n",
        "                               pl.Series(\"ld_pred_xgb\", ld_pred_all),\n",
        "                               pl.Series(\"fb_pred_xgb\", fb_pred_all),\n",
        "                               pl.Series(\"po_pred_xgb\", po_pred_all))"
      ],
      "metadata": {
        "id": "NR9Kpk1DSAYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'foul_pred_xgb', actuals = 'foul', model = 'XGBoost Batted Ball Model Calibrated Sigmoid (Foul)')"
      ],
      "metadata": {
        "id": "SO4fs_UNSAYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'gb_pred_xgb', actuals = 'ground_ball', model = 'XGBoost Batted Ball Model Calibrated Sigmoid (Ground Ball)')"
      ],
      "metadata": {
        "id": "B0wcqZ8iSAYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'ld_pred_xgb', actuals = 'line_drive', model = 'XGBoost Batted Ball Model Calibrated Sigmoid (Line Drive)')"
      ],
      "metadata": {
        "id": "8H4U3u58SAYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'fb_pred_xgb', actuals = 'fly_ball', model = 'XGBoost Batted Ball Model Calibrated Sigmoid (Fly Ball)')"
      ],
      "metadata": {
        "id": "MlTJ6HosSAYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'po_pred_xgb', actuals = 'popup', model = 'XGBoost Batted Ball Model Calibrated Sigmoid (Pop Up)')"
      ],
      "metadata": {
        "id": "KAOGZC6aSAYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Net 4 Layers"
      ],
      "metadata": {
        "id": "VepCaPSWXC8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural net 4 layer model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'bb_target'\n",
        "\n",
        "df_pandas = df_bb.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "foul_pred_all = np.zeros_like(y, dtype=float)\n",
        "gb_pred_all = np.zeros_like(y, dtype=float)\n",
        "ld_pred_all = np.zeros_like(y, dtype=float)\n",
        "fb_pred_all = np.zeros_like(y, dtype=float)\n",
        "po_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape = (X.shape[1],)),\n",
        "        Dense(128, activation = 'relu'),\n",
        "        Dense(64, activation = 'relu'),\n",
        "        Dense(32, activation = 'relu'),\n",
        "        Dense(5, activation = 'softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor = 'val_loss',\n",
        "        patience = 0,\n",
        "        restore_best_weights = True,\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train, validation_split = 0.2, callbacks = [early_stop], epochs = 15, batch_size = 1024, verbose = 1)\n",
        "\n",
        "    preds = model.predict(X_test_scaled)\n",
        "\n",
        "    foul_pred_all[test_idx] = preds[:, 0]\n",
        "    gb_pred_all[test_idx] = preds[:, 1]\n",
        "    ld_pred_all[test_idx] = preds[:, 2]\n",
        "    fb_pred_all[test_idx] = preds[:, 3]\n",
        "    po_pred_all[test_idx] = preds[:, 4]\n",
        "\n",
        "\n",
        "df_bb = df_bb.with_columns(pl.Series(\"foul_pred_nn\", foul_pred_all),\n",
        "                               pl.Series(\"gb_pred_nn\", gb_pred_all),\n",
        "                               pl.Series(\"ld_pred_nn\", ld_pred_all),\n",
        "                               pl.Series(\"fb_pred_nn\", fb_pred_all),\n",
        "                               pl.Series(\"po_pred_nn\", po_pred_all))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PEQ9ewNrSRn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'foul_pred_nn', actuals = 'foul', model = 'Neural Net 4 Layers Batted Ball Model (Foul)')"
      ],
      "metadata": {
        "id": "7O9JbajlXWCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'gb_pred_nn', actuals = 'ground_ball', model = 'Neural Net 4 Layers Batted Ball Model (Ground Ball)')"
      ],
      "metadata": {
        "id": "kZQJGN0tXYCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'ld_pred_nn', actuals = 'line_drive', model = 'Neural Net 4 Layers Batted Ball Model (Line Drive)')"
      ],
      "metadata": {
        "id": "_-qx6tlDXX7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'fb_pred_nn', actuals = 'fly_ball', model = 'Neural Net 4 Layers Batted Ball Model (Fly Ball)')"
      ],
      "metadata": {
        "id": "UPc0DLTSXX3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'po_pred_nn', actuals = 'popup', model = 'Neural Net 4 Layers Batted Ball Model (Pop Up)')"
      ],
      "metadata": {
        "id": "-IEoYFwbXXzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Net 3 Layers"
      ],
      "metadata": {
        "id": "PJ5DClm2bcsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural net 3 layer model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'bb_target'\n",
        "\n",
        "df_pandas = df_bb.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "foul_pred_all = np.zeros_like(y, dtype=float)\n",
        "gb_pred_all = np.zeros_like(y, dtype=float)\n",
        "ld_pred_all = np.zeros_like(y, dtype=float)\n",
        "fb_pred_all = np.zeros_like(y, dtype=float)\n",
        "po_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape = (X.shape[1],)),\n",
        "        Dense(64, activation = 'relu'),\n",
        "        Dense(32, activation = 'relu'),\n",
        "        Dense(5, activation = 'softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor = 'val_loss',\n",
        "        patience = 0,\n",
        "        restore_best_weights = True,\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train, validation_split = 0.2, callbacks = [early_stop], epochs = 15, batch_size = 1024, verbose = 1)\n",
        "\n",
        "    preds = model.predict(X_test_scaled)\n",
        "\n",
        "    foul_pred_all[test_idx] = preds[:, 0]\n",
        "    gb_pred_all[test_idx] = preds[:, 1]\n",
        "    ld_pred_all[test_idx] = preds[:, 2]\n",
        "    fb_pred_all[test_idx] = preds[:, 3]\n",
        "    po_pred_all[test_idx] = preds[:, 4]\n",
        "\n",
        "\n",
        "df_bb = df_bb.with_columns(pl.Series(\"foul_pred_nn\", foul_pred_all),\n",
        "                               pl.Series(\"gb_pred_nn\", gb_pred_all),\n",
        "                               pl.Series(\"ld_pred_nn\", ld_pred_all),\n",
        "                               pl.Series(\"fb_pred_nn\", fb_pred_all),\n",
        "                               pl.Series(\"po_pred_nn\", po_pred_all))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "pfZ8MlpRbBjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'foul_pred_nn', actuals = 'foul', model = 'Neural Net 3 Layers Batted Ball Model (Foul)')"
      ],
      "metadata": {
        "id": "DLF0rDtbblVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'gb_pred_nn', actuals = 'ground_ball', model = 'Neural Net 3 Layers Batted Ball Model (Ground Ball)')"
      ],
      "metadata": {
        "id": "z8GTxXPPblVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'ld_pred_nn', actuals = 'line_drive', model = 'Neural Net 3 Layers Batted Ball Model (Line Drive)')"
      ],
      "metadata": {
        "id": "e7Gwow1wblVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'fb_pred_nn', actuals = 'fly_ball', model = 'Neural Net 3 Layers Batted Ball Model (Fly Ball)')"
      ],
      "metadata": {
        "id": "DHO1MdcDblVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'po_pred_nn', actuals = 'popup', model = 'Neural Net 3 LayersBatted Ball Model (Pop Up)')"
      ],
      "metadata": {
        "id": "ISUHZjlKblVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Net 2 Layers"
      ],
      "metadata": {
        "id": "bhSnSlWDqDEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural net 2 layer model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'bb_target'\n",
        "\n",
        "df_pandas = df_bb.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "foul_pred_all = np.zeros_like(y, dtype=float)\n",
        "gb_pred_all = np.zeros_like(y, dtype=float)\n",
        "ld_pred_all = np.zeros_like(y, dtype=float)\n",
        "fb_pred_all = np.zeros_like(y, dtype=float)\n",
        "po_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape = (X.shape[1],)),\n",
        "        Dense(32, activation = 'relu'),\n",
        "        Dense(5, activation = 'softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor = 'val_loss',\n",
        "        patience = 0,\n",
        "        restore_best_weights = True,\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train, validation_split = 0.2, callbacks = [early_stop], epochs = 15, batch_size = 1024, verbose = 1)\n",
        "\n",
        "    preds = model.predict(X_test_scaled)\n",
        "\n",
        "    foul_pred_all[test_idx] = preds[:, 0]\n",
        "    gb_pred_all[test_idx] = preds[:, 1]\n",
        "    ld_pred_all[test_idx] = preds[:, 2]\n",
        "    fb_pred_all[test_idx] = preds[:, 3]\n",
        "    po_pred_all[test_idx] = preds[:, 4]\n",
        "\n",
        "\n",
        "df_bb = df_bb.with_columns(pl.Series(\"foul_pred_nn\", foul_pred_all),\n",
        "                               pl.Series(\"gb_pred_nn\", gb_pred_all),\n",
        "                               pl.Series(\"ld_pred_nn\", ld_pred_all),\n",
        "                               pl.Series(\"fb_pred_nn\", fb_pred_all),\n",
        "                               pl.Series(\"po_pred_nn\", po_pred_all))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2W3PJOOJqEGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'foul_pred_nn', actuals = 'foul', model = 'Neural Net 2 Layers Batted Ball Model (Foul)')"
      ],
      "metadata": {
        "id": "yWjqAdwvqKwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'gb_pred_nn', actuals = 'ground_ball', model = 'Neural Net 2 Layers Batted Ball Model (Ground Ball)')"
      ],
      "metadata": {
        "id": "31ba5XIyqKwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'ld_pred_nn', actuals = 'line_drive', model = 'Neural Net 2 Layers Batted Ball Model (Line Drive)')"
      ],
      "metadata": {
        "id": "Allu9rs7qKwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'fb_pred_nn', actuals = 'fly_ball', model = 'Neural Net 2 Layers Batted Ball Model (Fly Ball)')"
      ],
      "metadata": {
        "id": "7nEGM8D8qKwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_bb, preds = 'po_pred_nn', actuals = 'popup', model = 'Neural Net 2 Layers Batted Ball Model (Pop Up)')"
      ],
      "metadata": {
        "id": "-hsnUp2ZqKwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Groundball Model (4 Layer DNN)"
      ],
      "metadata": {
        "id": "JzvdHXx0dLCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filter to relevant rows\n",
        "df_gb = df.filter(pl.col('bb_type') == 'ground_ball')\n",
        "\n",
        "# create target col\n",
        "df_gb = df_gb.with_columns(\n",
        "    pl.when(pl.col('out') == 1)\n",
        "    .then(0)\n",
        "    .when(pl.col('single') == 1)\n",
        "    .then(1)\n",
        "    .when(pl.col('double') == 1)\n",
        "    .then(2)\n",
        "    .when(pl.col('triple') == 1)\n",
        "    .then(3)\n",
        "    .alias('gb_target')\n",
        ")"
      ],
      "metadata": {
        "id": "6fxbjHo-dlBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gb['out'].mean()"
      ],
      "metadata": {
        "id": "HgvmcEKYdtMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gb['single'].mean()"
      ],
      "metadata": {
        "id": "XbA-SRCPuEsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gb['double'].mean()"
      ],
      "metadata": {
        "id": "5VYXTm6UvWYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gb['triple'].mean()"
      ],
      "metadata": {
        "id": "9XCxYZXOvXzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "fFRuxnGUwEu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'gb_target'\n",
        "\n",
        "df_pandas = df_gb.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "model = XGBClassifier(objective = 'multi:softprob', num_class = 4, eval_metric = 'mlogloss')\n",
        "preds = cross_val_predict(model, X, y , cv=5, method='predict_proba')\n",
        "\n",
        "df_gb = df_gb.with_columns(pl.Series(\"out_pred_xgb\", preds[:, 0]),\n",
        "                               pl.Series(\"single_pred_xgb\", preds[:, 1]),\n",
        "                               pl.Series(\"double_pred_xgb\", preds[:, 2]),\n",
        "                               pl.Series(\"triple_pred_xgb\", preds[:, 3]))"
      ],
      "metadata": {
        "id": "fenwpnXVvl2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_gb, preds = 'out_pred_xgb', actuals = 'out', model = 'XGBoost Ground Ball Model (Outs)')"
      ],
      "metadata": {
        "id": "7V-nioqTwTnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_gb, preds = 'single_pred_xgb', actuals = 'single', model = 'XGBoost Ground Ball Model (Singles)')"
      ],
      "metadata": {
        "id": "aJqmfN_8wcwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_gb, preds = 'double_pred_xgb', actuals = 'double', model = 'XGBoost Ground Ball Model (Doubles)')"
      ],
      "metadata": {
        "id": "-i6J6kJ0wdwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_gb, preds = 'triple_pred_xgb', actuals = 'triple', model = 'XGBoost Ground Ball Model (Triples)')"
      ],
      "metadata": {
        "id": "YUFfvFCGwdsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost Isotonic"
      ],
      "metadata": {
        "id": "wZmT_n1-xGzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost isotonic model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'gb_target'\n",
        "\n",
        "df_pandas = df_gb.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "out_pred_all = np.zeros_like(y, dtype=float)\n",
        "single_pred_all = np.zeros_like(y, dtype=float)\n",
        "double_pred_all = np.zeros_like(y, dtype=float)\n",
        "triple_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    xgb = XGBClassifier(objective = 'multi:softprob', num_class = 4, eval_metric = 'mlogloss')\n",
        "\n",
        "    calibrated_xgb = CalibratedClassifierCV(xgb, method = 'isotonic', cv = 3)\n",
        "    calibrated_xgb.fit(X_train, y_train)\n",
        "\n",
        "    preds = calibrated_xgb.predict_proba(X_test)\n",
        "\n",
        "    out_pred_all[test_idx] = preds[:, 0]\n",
        "    single_pred_all[test_idx] = preds[:, 1]\n",
        "    double_pred_all[test_idx] = preds[:, 2]\n",
        "    triple_pred_all[test_idx] = preds[:, 3]\n",
        "\n",
        "df_gb = df_gb.with_columns(pl.Series(\"out_pred_xgb\", out_pred_all),\n",
        "                               pl.Series(\"single_pred_xgb\", single_pred_all),\n",
        "                               pl.Series(\"double_pred_xgb\", double_pred_all),\n",
        "                               pl.Series(\"triple_pred_xgb\", triple_pred_all))"
      ],
      "metadata": {
        "id": "cJPtIEPpwqjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_gb, preds = 'out_pred_xgb', actuals = 'out', model = 'XGBoost Ground Ball Model Isotonic Calibrated (Outs)')"
      ],
      "metadata": {
        "id": "15a-bNZQ5vJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_gb, preds = 'single_pred_xgb', actuals = 'single', model = 'XGBoost Ground Ball Model Isotonic Calibrated (Singles)')"
      ],
      "metadata": {
        "id": "p9RWIzGg53Cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_gb, preds = 'double_pred_xgb', actuals = 'double', model = 'XGBoost Ground Ball Model Isotonic Calibrated (Doubles)')"
      ],
      "metadata": {
        "id": "iQiJpJ8553Cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_gb, preds = 'triple_pred_xgb', actuals = 'triple', model = 'XGBoost Ground Ball Model Isotonic Calibrated (Triples)')"
      ],
      "metadata": {
        "id": "ygNoSC3653Cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost Sigmoid"
      ],
      "metadata": {
        "id": "VU2fOeqU6fSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost sigmoid model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'gb_target'\n",
        "\n",
        "df_pandas = df_gb.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "out_pred_all = np.zeros_like(y, dtype=float)\n",
        "single_pred_all = np.zeros_like(y, dtype=float)\n",
        "double_pred_all = np.zeros_like(y, dtype=float)\n",
        "triple_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    xgb = XGBClassifier(objective = 'multi:softprob', num_class = 4, eval_metric = 'mlogloss')\n",
        "\n",
        "    calibrated_xgb = CalibratedClassifierCV(xgb, method = 'sigmoid', cv = 3)\n",
        "    calibrated_xgb.fit(X_train, y_train)\n",
        "\n",
        "    preds = calibrated_xgb.predict_proba(X_test)\n",
        "\n",
        "    out_pred_all[test_idx] = preds[:, 0]\n",
        "    single_pred_all[test_idx] = preds[:, 1]\n",
        "    double_pred_all[test_idx] = preds[:, 2]\n",
        "    triple_pred_all[test_idx] = preds[:, 3]\n",
        "\n",
        "df_gb = df_gb.with_columns(pl.Series(\"out_pred_xgb\", out_pred_all),\n",
        "                               pl.Series(\"single_pred_xgb\", single_pred_all),\n",
        "                               pl.Series(\"double_pred_xgb\", double_pred_all),\n",
        "                               pl.Series(\"triple_pred_xgb\", triple_pred_all))"
      ],
      "metadata": {
        "id": "Adi8GboB6ZC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_gb, preds = 'out_pred_xgb', actuals = 'out', model = 'XGBoost Ground Ball Model Sigmoid Calibrated (Outs)')"
      ],
      "metadata": {
        "id": "XMsUo0kQ6i-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_gb, preds = 'single_pred_xgb', actuals = 'single', model = 'XGBoost Ground Ball Model Sigmoid Calibrated (Singles)')"
      ],
      "metadata": {
        "id": "Diglrcbq6i-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_gb, preds = 'double_pred_xgb', actuals = 'double', model = 'XGBoost Ground Ball Model Sigmoid Calibrated (Doubles)')"
      ],
      "metadata": {
        "id": "VVCgdFiR6i-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_gb, preds = 'triple_pred_xgb', actuals = 'triple', model = 'XGBoost Ground Ball Model Sigmoid Calibrated (Triples)')"
      ],
      "metadata": {
        "id": "mmu0geft6i-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Net 4 Layers"
      ],
      "metadata": {
        "id": "Ae6QXn-z7QkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural net 4 layer model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'gb_target'\n",
        "\n",
        "df_pandas = df_gb.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "out_pred_all = np.zeros_like(y, dtype=float)\n",
        "single_pred_all = np.zeros_like(y, dtype=float)\n",
        "double_pred_all = np.zeros_like(y, dtype=float)\n",
        "triple_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape = (X.shape[1],)),\n",
        "        Dense(128, activation = 'relu'),\n",
        "        Dense(64, activation = 'relu'),\n",
        "        Dense(32, activation = 'relu'),\n",
        "        Dense(4, activation = 'softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor = 'val_loss',\n",
        "        patience = 0,\n",
        "        restore_best_weights = True,\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train, validation_split = 0.2, callbacks = [early_stop], epochs = 15, batch_size = 1024, verbose = 1)\n",
        "\n",
        "    preds = model.predict(X_test_scaled)\n",
        "\n",
        "    out_pred_all[test_idx] = preds[:, 0]\n",
        "    single_pred_all[test_idx] = preds[:, 1]\n",
        "    double_pred_all[test_idx] = preds[:, 2]\n",
        "    triple_pred_all[test_idx] = preds[:, 3]\n",
        "\n",
        "\n",
        "df_gb = df_gb.with_columns(pl.Series(\"out_pred_nn\", out_pred_all),\n",
        "                               pl.Series(\"single_pred_nn\", single_pred_all),\n",
        "                               pl.Series(\"double_pred_nn\", double_pred_all),\n",
        "                               pl.Series(\"triple_pred_nn\", triple_pred_all))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "sMg3gELB7JH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_gb, preds = 'out_pred_nn', actuals = 'out', model = 'Neural Net 4 Layers Ground Ball Model (Outs)')"
      ],
      "metadata": {
        "id": "vx9foWZd9Kz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_gb, preds = 'single_pred_nn', actuals = 'single', model = 'Neural Net 4 Layers Ground Ball Model (Singles)')"
      ],
      "metadata": {
        "id": "AFx6DF329Kz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_gb, preds = 'double_pred_nn', actuals = 'double', model = 'Neural Net 4 Layers Ground Ball Model (Doubles)')"
      ],
      "metadata": {
        "id": "LNFJNZx29Kz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_gb, preds = 'triple_pred_nn', actuals = 'triple', model = 'Neural Net 4 Layers Ground Ball Model (Triples)')"
      ],
      "metadata": {
        "id": "3xRScmBO9K0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Net 3 Layers"
      ],
      "metadata": {
        "id": "ouhgBw0h9qrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural net 3 layer model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'gb_target'\n",
        "\n",
        "df_pandas = df_gb.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "out_pred_all = np.zeros_like(y, dtype=float)\n",
        "single_pred_all = np.zeros_like(y, dtype=float)\n",
        "double_pred_all = np.zeros_like(y, dtype=float)\n",
        "triple_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape = (X.shape[1],)),\n",
        "        Dense(64, activation = 'relu'),\n",
        "        Dense(32, activation = 'relu'),\n",
        "        Dense(4, activation = 'softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor = 'val_loss',\n",
        "        patience = 0,\n",
        "        restore_best_weights = True,\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train, validation_split = 0.2, callbacks = [early_stop], epochs = 15, batch_size = 1024, verbose = 1)\n",
        "\n",
        "    preds = model.predict(X_test_scaled)\n",
        "\n",
        "    out_pred_all[test_idx] = preds[:, 0]\n",
        "    single_pred_all[test_idx] = preds[:, 1]\n",
        "    double_pred_all[test_idx] = preds[:, 2]\n",
        "    triple_pred_all[test_idx] = preds[:, 3]\n",
        "\n",
        "\n",
        "df_gb = df_gb.with_columns(pl.Series(\"out_pred_nn\", out_pred_all),\n",
        "                               pl.Series(\"single_pred_nn\", single_pred_all),\n",
        "                               pl.Series(\"double_pred_nn\", double_pred_all),\n",
        "                               pl.Series(\"triple_pred_nn\", triple_pred_all))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Jsj6bRXZ9r1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_gb, preds = 'out_pred_nn', actuals = 'out', model = 'Neural Net 3 Layers Ground Ball Model (Outs)')"
      ],
      "metadata": {
        "id": "a41qrLnN9r1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_gb, preds = 'single_pred_nn', actuals = 'single', model = 'Neural Net 3 Layers Ground Ball Model (Singles)')"
      ],
      "metadata": {
        "id": "uN3efnTV9r1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_gb, preds = 'double_pred_nn', actuals = 'double', model = 'Neural Net 3 Layers Ground Ball Model (Doubles)')"
      ],
      "metadata": {
        "id": "Bjnkf_jq9r1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_gb, preds = 'triple_pred_nn', actuals = 'triple', model = 'Neural Net 3 Layers Ground Ball Model (Triples)')"
      ],
      "metadata": {
        "id": "xj2Z3HQU9r1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Net 2 Layers"
      ],
      "metadata": {
        "id": "H_0Awucf-mLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural net 2 layer model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'gb_target'\n",
        "\n",
        "df_pandas = df_gb.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "out_pred_all = np.zeros_like(y, dtype=float)\n",
        "single_pred_all = np.zeros_like(y, dtype=float)\n",
        "double_pred_all = np.zeros_like(y, dtype=float)\n",
        "triple_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape = (X.shape[1],)),\n",
        "        Dense(32, activation = 'relu'),\n",
        "        Dense(4, activation = 'softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor = 'val_loss',\n",
        "        patience = 0,\n",
        "        restore_best_weights = True,\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train, validation_split = 0.2, callbacks = [early_stop], epochs = 15, batch_size = 1024, verbose = 1)\n",
        "\n",
        "    preds = model.predict(X_test_scaled)\n",
        "\n",
        "    out_pred_all[test_idx] = preds[:, 0]\n",
        "    single_pred_all[test_idx] = preds[:, 1]\n",
        "    double_pred_all[test_idx] = preds[:, 2]\n",
        "    triple_pred_all[test_idx] = preds[:, 3]\n",
        "\n",
        "\n",
        "df_gb = df_gb.with_columns(pl.Series(\"out_pred_nn\", out_pred_all),\n",
        "                               pl.Series(\"single_pred_nn\", single_pred_all),\n",
        "                               pl.Series(\"double_pred_nn\", double_pred_all),\n",
        "                               pl.Series(\"triple_pred_nn\", triple_pred_all))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LKmdRrBN9xUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_gb, preds = 'out_pred_nn', actuals = 'out', model = 'Neural Net 2 Layers Ground Ball Model (Outs)')"
      ],
      "metadata": {
        "id": "_MicCMin-rh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_gb, preds = 'single_pred_nn', actuals = 'single', model = 'Neural Net 2 Layers Ground Ball Model (Singles)')"
      ],
      "metadata": {
        "id": "gnaUnwmg-rh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_gb, preds = 'double_pred_nn', actuals = 'double', model = 'Neural Net 2 Layers Ground Ball Model (Doubles)')"
      ],
      "metadata": {
        "id": "zRE_Td5F-rh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_gb, preds = 'triple_pred_nn', actuals = 'triple', model = 'Neural Net 2 Layers Ground Ball Model (Triples)')"
      ],
      "metadata": {
        "id": "_wDTvuDR-rh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Line Drive Model (2 Layer DNN)"
      ],
      "metadata": {
        "id": "7CaoZe6KBGRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filter to relevant rows\n",
        "df_ld = df.filter(pl.col('bb_type') == 'line_drive')\n",
        "\n",
        "# create target col\n",
        "df_ld = df_ld.with_columns(\n",
        "    pl.when(pl.col('out') == 1)\n",
        "    .then(0)\n",
        "    .when(pl.col('single') == 1)\n",
        "    .then(1)\n",
        "    .when(pl.col('double') == 1)\n",
        "    .then(2)\n",
        "    .when(pl.col('triple') == 1)\n",
        "    .then(3)\n",
        "    .when(pl.col('home_run') == 1)\n",
        "    .then(4)\n",
        "    .alias('ld_target')\n",
        ")"
      ],
      "metadata": {
        "id": "772d1jsNBNdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ld['out'].mean()"
      ],
      "metadata": {
        "id": "drOCpozsBNdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ld['single'].mean()"
      ],
      "metadata": {
        "id": "NyjyMFPIBNdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ld['double'].mean()"
      ],
      "metadata": {
        "id": "5yMPw8aqBNdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ld['triple'].mean()"
      ],
      "metadata": {
        "id": "to5KgXdbBNdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ld['home_run'].mean()"
      ],
      "metadata": {
        "id": "ucL_WHReBXQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "xwRfmTN3Bc5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'ld_target'\n",
        "\n",
        "df_pandas = df_ld.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "model = XGBClassifier(objective = 'multi:softprob', num_class = 5, eval_metric = 'mlogloss')\n",
        "preds = cross_val_predict(model, X, y , cv=5, method='predict_proba')\n",
        "\n",
        "df_ld = df_ld.with_columns(pl.Series(\"out_pred_xgb\", preds[:, 0]),\n",
        "                            pl.Series(\"single_pred_xgb\", preds[:, 1]),\n",
        "                            pl.Series(\"double_pred_xgb\", preds[:, 2]),\n",
        "                            pl.Series(\"triple_pred_xgb\", preds[:, 3]),\n",
        "                            pl.Series(\"homerun_pred_xgb\", preds[:, 4]))"
      ],
      "metadata": {
        "id": "46YP8hu6Bd52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_ld, preds = 'out_pred_xgb', actuals = 'out', model = 'XGBoost Line Drive Model (Outs)')"
      ],
      "metadata": {
        "id": "2jAYyIoDBd52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_ld, preds = 'single_pred_xgb', actuals = 'single', model = 'XGBoost Line Drive Model (Singles)')"
      ],
      "metadata": {
        "id": "bH2d_nKfBd52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_ld, preds = 'double_pred_xgb', actuals = 'double', model = 'XGBoost Line Drive Model (Doubles)')"
      ],
      "metadata": {
        "id": "3jOvWLEqBd52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_ld, preds = 'triple_pred_xgb', actuals = 'triple', model = 'XGBoost Line Drive Model (Triples)')"
      ],
      "metadata": {
        "id": "Ot2Tt21hBd52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_ld, preds = 'homerun_pred_xgb', actuals = 'home_run', model = 'XGBoost Line Drive Model (Home Runs)')"
      ],
      "metadata": {
        "id": "28WPMzAGCahc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost Isotonic"
      ],
      "metadata": {
        "id": "sJAC-BGHCg5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost isotonic model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'ld_target'\n",
        "\n",
        "df_pandas = df_ld.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "out_pred_all = np.zeros_like(y, dtype=float)\n",
        "single_pred_all = np.zeros_like(y, dtype=float)\n",
        "double_pred_all = np.zeros_like(y, dtype=float)\n",
        "triple_pred_all = np.zeros_like(y, dtype=float)\n",
        "homerun_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    xgb = XGBClassifier(objective = 'multi:softprob', num_class = 5, eval_metric = 'mlogloss')\n",
        "\n",
        "    calibrated_xgb = CalibratedClassifierCV(xgb, method = 'isotonic', cv = 3)\n",
        "    calibrated_xgb.fit(X_train, y_train)\n",
        "\n",
        "    preds = calibrated_xgb.predict_proba(X_test)\n",
        "\n",
        "    out_pred_all[test_idx] = preds[:, 0]\n",
        "    single_pred_all[test_idx] = preds[:, 1]\n",
        "    double_pred_all[test_idx] = preds[:, 2]\n",
        "    triple_pred_all[test_idx] = preds[:, 3]\n",
        "    homerun_pred_all[test_idx] = preds[:, 4]\n",
        "\n",
        "df_ld = df_ld.with_columns(pl.Series(\"out_pred_xgb\", out_pred_all),\n",
        "                               pl.Series(\"single_pred_xgb\", single_pred_all),\n",
        "                               pl.Series(\"double_pred_xgb\", double_pred_all),\n",
        "                               pl.Series(\"triple_pred_xgb\", triple_pred_all),\n",
        "                           pl.Series(\"homerun_pred_xgb\", homerun_pred_all))"
      ],
      "metadata": {
        "id": "iy8ESP6pCf4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_ld, preds = 'out_pred_xgb', actuals = 'out', model = 'XGBoost Line Drive Model Isotonic Calibrated (Outs)')"
      ],
      "metadata": {
        "id": "IclC37XgGqlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_ld, preds = 'single_pred_xgb', actuals = 'single', model = 'XGBoost Line Drive Model Isotonic Calibrated (Singles)')"
      ],
      "metadata": {
        "id": "-8uEcIgXGqlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_ld, preds = 'double_pred_xgb', actuals = 'double', model = 'XGBoost Line Drive Model Isotonic Calibrated (Doubles)')"
      ],
      "metadata": {
        "id": "wOSluJKTGqlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_ld, preds = 'triple_pred_xgb', actuals = 'triple', model = 'XGBoost Line Drive Model Isotonic Calibrated (Triples)')"
      ],
      "metadata": {
        "id": "05nvIT8pGqlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_ld, preds = 'homerun_pred_xgb', actuals = 'home_run', model = 'XGBoost Line Drive Model Isotonic Calibrated (Home Runs)')"
      ],
      "metadata": {
        "id": "GzHqnhTLGqlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost Sigmoid"
      ],
      "metadata": {
        "id": "th7-vAcvHaIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost sigmoid model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'ld_target'\n",
        "\n",
        "df_pandas = df_ld.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "out_pred_all = np.zeros_like(y, dtype=float)\n",
        "single_pred_all = np.zeros_like(y, dtype=float)\n",
        "double_pred_all = np.zeros_like(y, dtype=float)\n",
        "triple_pred_all = np.zeros_like(y, dtype=float)\n",
        "homerun_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    xgb = XGBClassifier(objective = 'multi:softprob', num_class = 5, eval_metric = 'mlogloss')\n",
        "\n",
        "    calibrated_xgb = CalibratedClassifierCV(xgb, method = 'sigmoid', cv = 3)\n",
        "    calibrated_xgb.fit(X_train, y_train)\n",
        "\n",
        "    preds = calibrated_xgb.predict_proba(X_test)\n",
        "\n",
        "    out_pred_all[test_idx] = preds[:, 0]\n",
        "    single_pred_all[test_idx] = preds[:, 1]\n",
        "    double_pred_all[test_idx] = preds[:, 2]\n",
        "    triple_pred_all[test_idx] = preds[:, 3]\n",
        "    homerun_pred_all[test_idx] = preds[:, 4]\n",
        "\n",
        "df_ld = df_ld.with_columns(pl.Series(\"out_pred_xgb\", out_pred_all),\n",
        "                               pl.Series(\"single_pred_xgb\", single_pred_all),\n",
        "                               pl.Series(\"double_pred_xgb\", double_pred_all),\n",
        "                               pl.Series(\"triple_pred_xgb\", triple_pred_all),\n",
        "                           pl.Series(\"homerun_pred_xgb\", homerun_pred_all))"
      ],
      "metadata": {
        "id": "JGGOl2o-HbR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_ld, preds = 'out_pred_xgb', actuals = 'out', model = 'XGBoost Line Drive Model Sigmoid Calibrated (Outs)')"
      ],
      "metadata": {
        "id": "7NE81x_LHbR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_ld, preds = 'single_pred_xgb', actuals = 'single', model = 'XGBoost Line Drive Model Sigmoid Calibrated (Singles)')"
      ],
      "metadata": {
        "id": "8u6zGXzFHbR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_ld, preds = 'double_pred_xgb', actuals = 'double', model = 'XGBoost Line Drive Model Sigmoid Calibrated (Doubles)')"
      ],
      "metadata": {
        "id": "0u6GyEx4HbR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_ld, preds = 'triple_pred_xgb', actuals = 'triple', model = 'XGBoost Line Drive Model Sigmoid Calibrated (Triples)')"
      ],
      "metadata": {
        "id": "PLtGnxFCHbR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_ld, preds = 'homerun_pred_xgb', actuals = 'home_run', model = 'XGBoost Line Drive Model Sigmoid Calibrated (Home Runs)')"
      ],
      "metadata": {
        "id": "6NcGzW5DHbR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Net 2 Layers"
      ],
      "metadata": {
        "id": "4z3JPO_pJd7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural net 2 layer model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'ld_target'\n",
        "\n",
        "df_pandas = df_ld.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "out_pred_all = np.zeros_like(y, dtype=float)\n",
        "single_pred_all = np.zeros_like(y, dtype=float)\n",
        "double_pred_all = np.zeros_like(y, dtype=float)\n",
        "triple_pred_all = np.zeros_like(y, dtype=float)\n",
        "homerun_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape = (X.shape[1],)),\n",
        "        Dense(32, activation = 'relu'),\n",
        "        Dense(5, activation = 'softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor = 'val_loss',\n",
        "        patience = 0,\n",
        "        restore_best_weights = True,\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train, validation_split = 0.2, callbacks = [early_stop], epochs = 15, batch_size = 1024, verbose = 1)\n",
        "\n",
        "    preds = model.predict(X_test_scaled)\n",
        "\n",
        "    out_pred_all[test_idx] = preds[:, 0]\n",
        "    single_pred_all[test_idx] = preds[:, 1]\n",
        "    double_pred_all[test_idx] = preds[:, 2]\n",
        "    triple_pred_all[test_idx] = preds[:, 3]\n",
        "    homerun_pred_all[test_idx] = preds[:, 4]\n",
        "\n",
        "\n",
        "df_ld = df_ld.with_columns(pl.Series(\"out_pred_nn\", out_pred_all),\n",
        "                               pl.Series(\"single_pred_nn\", single_pred_all),\n",
        "                               pl.Series(\"double_pred_nn\", double_pred_all),\n",
        "                               pl.Series(\"triple_pred_nn\", triple_pred_all),\n",
        "                           pl.Series(\"homerun_pred_nn\", homerun_pred_all))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "saD6VnH0Jfdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_ld, preds = 'out_pred_nn', actuals = 'out', model = 'Neural Net 2 Layers Line Drive Model (Outs)')"
      ],
      "metadata": {
        "id": "CEUHFJN1Jfde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_ld, preds = 'single_pred_nn', actuals = 'single', model = 'Neural Net 2 Layers Line Drive Model (Singles)')"
      ],
      "metadata": {
        "id": "Hj458pq2Jfde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_ld, preds = 'double_pred_nn', actuals = 'double', model = 'Neural Net 2 Layers Line Drive Model (Doubles)')"
      ],
      "metadata": {
        "id": "zO8wPaNUJfde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_ld, preds = 'triple_pred_nn', actuals = 'triple', model = 'Neural Net 2 Layers Line Drive Model (Triples)')"
      ],
      "metadata": {
        "id": "yJIn0-hFJfde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_ld, preds = 'homerun_pred_nn', actuals = 'home_run', model = 'Neural Net 2 Layers Line Drive Model (Home Runs)')"
      ],
      "metadata": {
        "id": "RTxWxtxLJska"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Net 3 Layers"
      ],
      "metadata": {
        "id": "GiOuNwM2Kqs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural net 3 layer model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'ld_target'\n",
        "\n",
        "df_pandas = df_ld.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "out_pred_all = np.zeros_like(y, dtype=float)\n",
        "single_pred_all = np.zeros_like(y, dtype=float)\n",
        "double_pred_all = np.zeros_like(y, dtype=float)\n",
        "triple_pred_all = np.zeros_like(y, dtype=float)\n",
        "homerun_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape = (X.shape[1],)),\n",
        "        Dense(64, activation = 'relu'),\n",
        "        Dense(32, activation = 'relu'),\n",
        "        Dense(5, activation = 'softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor = 'val_loss',\n",
        "        patience = 0,\n",
        "        restore_best_weights = True,\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train, validation_split = 0.2, callbacks = [early_stop], epochs = 15, batch_size = 1024, verbose = 1)\n",
        "\n",
        "    preds = model.predict(X_test_scaled)\n",
        "\n",
        "    out_pred_all[test_idx] = preds[:, 0]\n",
        "    single_pred_all[test_idx] = preds[:, 1]\n",
        "    double_pred_all[test_idx] = preds[:, 2]\n",
        "    triple_pred_all[test_idx] = preds[:, 3]\n",
        "    homerun_pred_all[test_idx] = preds[:, 4]\n",
        "\n",
        "\n",
        "df_ld = df_ld.with_columns(pl.Series(\"out_pred_nn\", out_pred_all),\n",
        "                               pl.Series(\"single_pred_nn\", single_pred_all),\n",
        "                               pl.Series(\"double_pred_nn\", double_pred_all),\n",
        "                               pl.Series(\"triple_pred_nn\", triple_pred_all),\n",
        "                           pl.Series(\"homerun_pred_nn\", homerun_pred_all))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9WPZJAHGJ8gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_ld, preds = 'out_pred_nn', actuals = 'out', model = 'Neural Net 3 Layers Line Drive Model (Outs)')"
      ],
      "metadata": {
        "id": "GOzumsSBK4S7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_ld, preds = 'single_pred_nn', actuals = 'single', model = 'Neural Net 3 Layers Line Drive Model (Singles)')"
      ],
      "metadata": {
        "id": "HrogprJEK4S7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_ld, preds = 'double_pred_nn', actuals = 'double', model = 'Neural Net 3 Layers Line Drive Model (Doubles)')"
      ],
      "metadata": {
        "id": "WazE0vkBK4S7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_ld, preds = 'triple_pred_nn', actuals = 'triple', model = 'Neural Net 3 Layers Line Drive Model (Triples)')"
      ],
      "metadata": {
        "id": "H3gyt6zCK4S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_ld, preds = 'homerun_pred_nn', actuals = 'home_run', model = 'Neural Net 3 Layers Line Drive Model (Home Runs)')"
      ],
      "metadata": {
        "id": "9-hVvL87K4S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Flyball Model (2 Layer DNN)"
      ],
      "metadata": {
        "id": "Thruzq_DMFWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filter to relevant rows\n",
        "df_fb = df.filter(pl.col('bb_type') == 'fly_ball')\n",
        "\n",
        "# create target col\n",
        "df_fb = df_fb.with_columns(\n",
        "    pl.when(pl.col('out') == 1)\n",
        "    .then(0)\n",
        "    .when(pl.col('single') == 1)\n",
        "    .then(1)\n",
        "    .when(pl.col('double') == 1)\n",
        "    .then(2)\n",
        "    .when(pl.col('triple') == 1)\n",
        "    .then(3)\n",
        "    .when(pl.col('home_run') == 1)\n",
        "    .then(4)\n",
        "    .alias('fb_target')\n",
        ")"
      ],
      "metadata": {
        "id": "vZ70zZL0MK0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fb['out'].mean()"
      ],
      "metadata": {
        "id": "k9U7n32OMK0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fb['single'].mean()"
      ],
      "metadata": {
        "id": "h3dvD12BMK0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fb['double'].mean()"
      ],
      "metadata": {
        "id": "Dbianv8YMK0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fb['triple'].mean()"
      ],
      "metadata": {
        "id": "xL6vG5auMK0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fb['home_run'].mean()"
      ],
      "metadata": {
        "id": "5FzrV4WPMK0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "Lwc5paK6MXTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'fb_target'\n",
        "\n",
        "df_pandas = df_fb.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "model = XGBClassifier(objective = 'multi:softprob', num_class = 5, eval_metric = 'mlogloss')\n",
        "preds = cross_val_predict(model, X, y , cv=5, method='predict_proba')\n",
        "\n",
        "df_fb = df_fb.with_columns(pl.Series(\"out_pred_xgb\", preds[:, 0]),\n",
        "                            pl.Series(\"single_pred_xgb\", preds[:, 1]),\n",
        "                            pl.Series(\"double_pred_xgb\", preds[:, 2]),\n",
        "                            pl.Series(\"triple_pred_xgb\", preds[:, 3]),\n",
        "                            pl.Series(\"homerun_pred_xgb\", preds[:, 4]))"
      ],
      "metadata": {
        "id": "BQhLrdtcMcQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_fb, preds = 'out_pred_xgb', actuals = 'out', model = 'XGBoost Fly Ball Model (Outs)')"
      ],
      "metadata": {
        "id": "zm_OrGVcMcQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_fb, preds = 'single_pred_xgb', actuals = 'single', model = 'XGBoost Fly Ball Model (Singles)')"
      ],
      "metadata": {
        "id": "dwc_doqCMcQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_fb, preds = 'double_pred_xgb', actuals = 'double', model = 'XGBoost Fly Ball Model (Doubles)')"
      ],
      "metadata": {
        "id": "pqxBfoFZMcQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_fb, preds = 'triple_pred_xgb', actuals = 'triple', model = 'XGBoost Fly Ball Model (Triples)')"
      ],
      "metadata": {
        "id": "9WDgeFA9McQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_fb, preds = 'homerun_pred_xgb', actuals = 'home_run', model = 'XGBoost Fly Ball Model (Home Runs)')"
      ],
      "metadata": {
        "id": "UkNoYISjMcQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost Isotonic"
      ],
      "metadata": {
        "id": "XfZfQsj6Nd96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost isotonic model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'fb_target'\n",
        "\n",
        "df_pandas = df_fb.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "out_pred_all = np.zeros_like(y, dtype=float)\n",
        "single_pred_all = np.zeros_like(y, dtype=float)\n",
        "double_pred_all = np.zeros_like(y, dtype=float)\n",
        "triple_pred_all = np.zeros_like(y, dtype=float)\n",
        "homerun_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    xgb = XGBClassifier(objective = 'multi:softprob', num_class = 5, eval_metric = 'mlogloss')\n",
        "\n",
        "    calibrated_xgb = CalibratedClassifierCV(xgb, method = 'isotonic', cv = 3)\n",
        "    calibrated_xgb.fit(X_train, y_train)\n",
        "\n",
        "    preds = calibrated_xgb.predict_proba(X_test)\n",
        "\n",
        "    out_pred_all[test_idx] = preds[:, 0]\n",
        "    single_pred_all[test_idx] = preds[:, 1]\n",
        "    double_pred_all[test_idx] = preds[:, 2]\n",
        "    triple_pred_all[test_idx] = preds[:, 3]\n",
        "    homerun_pred_all[test_idx] = preds[:, 4]\n",
        "\n",
        "df_fb = df_fb.with_columns(pl.Series(\"out_pred_xgb\", out_pred_all),\n",
        "                               pl.Series(\"single_pred_xgb\", single_pred_all),\n",
        "                               pl.Series(\"double_pred_xgb\", double_pred_all),\n",
        "                               pl.Series(\"triple_pred_xgb\", triple_pred_all),\n",
        "                           pl.Series(\"homerun_pred_xgb\", homerun_pred_all))"
      ],
      "metadata": {
        "id": "CwhpaVeXMvwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_fb, preds = 'out_pred_xgb', actuals = 'out', model = 'XGBoost Fly Ball Model Isotonic Calibrated (Outs)')"
      ],
      "metadata": {
        "id": "UcVgofINNsPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_fb, preds = 'single_pred_xgb', actuals = 'single', model = 'XGBoost Fly Ball Model Isotonic Calibrated (Singles)')"
      ],
      "metadata": {
        "id": "rcl9hRDONsPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_fb, preds = 'double_pred_xgb', actuals = 'double', model = 'XGBoost Fly Ball Model Isotonic Calibrated (Doubles)')"
      ],
      "metadata": {
        "id": "nl7c3TuINsPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_fb, preds = 'triple_pred_xgb', actuals = 'triple', model = 'XGBoost Fly Ball Model Isotonic Calibrated (Triples)')"
      ],
      "metadata": {
        "id": "GGwwkYxLNsPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_fb, preds = 'homerun_pred_xgb', actuals = 'home_run', model = 'XGBoost Fly Ball Model Isotonic Calibrated (Home Runs)')"
      ],
      "metadata": {
        "id": "mMJmCzhSNsPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost Sigmoid"
      ],
      "metadata": {
        "id": "AugBSHhBOqaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost sigmoid model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'fb_target'\n",
        "\n",
        "df_pandas = df_fb.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "out_pred_all = np.zeros_like(y, dtype=float)\n",
        "single_pred_all = np.zeros_like(y, dtype=float)\n",
        "double_pred_all = np.zeros_like(y, dtype=float)\n",
        "triple_pred_all = np.zeros_like(y, dtype=float)\n",
        "homerun_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    xgb = XGBClassifier(objective = 'multi:softprob', num_class = 5, eval_metric = 'mlogloss')\n",
        "\n",
        "    calibrated_xgb = CalibratedClassifierCV(xgb, method = 'sigmoid', cv = 3)\n",
        "    calibrated_xgb.fit(X_train, y_train)\n",
        "\n",
        "    preds = calibrated_xgb.predict_proba(X_test)\n",
        "\n",
        "    out_pred_all[test_idx] = preds[:, 0]\n",
        "    single_pred_all[test_idx] = preds[:, 1]\n",
        "    double_pred_all[test_idx] = preds[:, 2]\n",
        "    triple_pred_all[test_idx] = preds[:, 3]\n",
        "    homerun_pred_all[test_idx] = preds[:, 4]\n",
        "\n",
        "df_fb = df_fb.with_columns(pl.Series(\"out_pred_xgb\", out_pred_all),\n",
        "                               pl.Series(\"single_pred_xgb\", single_pred_all),\n",
        "                               pl.Series(\"double_pred_xgb\", double_pred_all),\n",
        "                               pl.Series(\"triple_pred_xgb\", triple_pred_all),\n",
        "                           pl.Series(\"homerun_pred_xgb\", homerun_pred_all))"
      ],
      "metadata": {
        "id": "cXrSXgUaNywF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_fb, preds = 'out_pred_xgb', actuals = 'out', model = 'XGBoost Fly Ball Model Sigmoid Calibrated (Outs)')"
      ],
      "metadata": {
        "id": "N1cmj5SqOw8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_fb, preds = 'single_pred_xgb', actuals = 'single', model = 'XGBoost Fly Ball Model Sigmoid Calibrated (Singles)')"
      ],
      "metadata": {
        "id": "YU7HMApJOw8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_fb, preds = 'double_pred_xgb', actuals = 'double', model = 'XGBoost Fly Ball Model Sigmoid Calibrated (Doubles)')"
      ],
      "metadata": {
        "id": "3SrlNQMgOw8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_fb, preds = 'triple_pred_xgb', actuals = 'triple', model = 'XGBoost Fly Ball Model Sigmoid Calibrated (Triples)')"
      ],
      "metadata": {
        "id": "SrWM2aoZOw8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_fb, preds = 'homerun_pred_xgb', actuals = 'home_run', model = 'XGBoost Fly Ball Model Sigmoid Calibrated (Home Runs)')"
      ],
      "metadata": {
        "id": "1bjrnVMjOw8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Net 2 Layers"
      ],
      "metadata": {
        "id": "gMyzFqRRRM-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural net 2 layer model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'fb_target'\n",
        "\n",
        "df_pandas = df_fb.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "out_pred_all = np.zeros_like(y, dtype=float)\n",
        "single_pred_all = np.zeros_like(y, dtype=float)\n",
        "double_pred_all = np.zeros_like(y, dtype=float)\n",
        "triple_pred_all = np.zeros_like(y, dtype=float)\n",
        "homerun_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape = (X.shape[1],)),\n",
        "        Dense(32, activation = 'relu'),\n",
        "        Dense(5, activation = 'softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor = 'val_loss',\n",
        "        patience = 1,\n",
        "        restore_best_weights = True,\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train, validation_split = 0.2, callbacks = [early_stop], epochs = 15, batch_size = 64, verbose = 1)\n",
        "\n",
        "    preds = model.predict(X_test_scaled)\n",
        "\n",
        "    out_pred_all[test_idx] = preds[:, 0]\n",
        "    single_pred_all[test_idx] = preds[:, 1]\n",
        "    double_pred_all[test_idx] = preds[:, 2]\n",
        "    triple_pred_all[test_idx] = preds[:, 3]\n",
        "    homerun_pred_all[test_idx] = preds[:, 4]\n",
        "\n",
        "\n",
        "df_fb = df_fb.with_columns(pl.Series(\"out_pred_nn\", out_pred_all),\n",
        "                               pl.Series(\"single_pred_nn\", single_pred_all),\n",
        "                               pl.Series(\"double_pred_nn\", double_pred_all),\n",
        "                               pl.Series(\"triple_pred_nn\", triple_pred_all),\n",
        "                           pl.Series(\"homerun_pred_nn\", homerun_pred_all))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "BIYwl0brTLhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_fb, preds = 'out_pred_nn', actuals = 'out', model = 'Neural Net 2 Layers Fly Ball Model (Outs)')"
      ],
      "metadata": {
        "id": "g97vR3GpTLhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_fb, preds = 'single_pred_nn', actuals = 'single', model = 'Neural Net 2 Layers Fly Ball Model (Singles)')"
      ],
      "metadata": {
        "id": "m9xEr8aVTLhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_fb, preds = 'double_pred_nn', actuals = 'double', model = 'Neural Net 2 Layers Fly Ball Model (Doubles)')"
      ],
      "metadata": {
        "id": "El8fmskZTLhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_fb, preds = 'triple_pred_nn', actuals = 'triple', model = 'Neural Net 2 Layers Fly Ball Model (Triples)')"
      ],
      "metadata": {
        "id": "EhlF_BByTLhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_fb, preds = 'homerun_pred_nn', actuals = 'home_run', model = 'Neural Net 2 Layers Fly Ball Model (Home Runs)')"
      ],
      "metadata": {
        "id": "8eOnOyvWTLhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Net 4 Layers"
      ],
      "metadata": {
        "id": "O0gumSQemZVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural net 4 layer model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'fb_target'\n",
        "\n",
        "df_pandas = df_fb.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "out_pred_all = np.zeros_like(y, dtype=float)\n",
        "single_pred_all = np.zeros_like(y, dtype=float)\n",
        "double_pred_all = np.zeros_like(y, dtype=float)\n",
        "triple_pred_all = np.zeros_like(y, dtype=float)\n",
        "homerun_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape = (X.shape[1],)),\n",
        "        Dense(128, activation = 'relu'),\n",
        "        Dense(64, activation = 'relu'),\n",
        "        Dense(32, activation = 'relu'),\n",
        "        Dense(5, activation = 'softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor = 'val_loss',\n",
        "        patience = 1,\n",
        "        restore_best_weights = True,\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train, validation_split = 0.2, callbacks = [early_stop], epochs = 15, batch_size = 64, verbose = 1)\n",
        "\n",
        "    preds = model.predict(X_test_scaled)\n",
        "\n",
        "    out_pred_all[test_idx] = preds[:, 0]\n",
        "    single_pred_all[test_idx] = preds[:, 1]\n",
        "    double_pred_all[test_idx] = preds[:, 2]\n",
        "    triple_pred_all[test_idx] = preds[:, 3]\n",
        "    homerun_pred_all[test_idx] = preds[:, 4]\n",
        "\n",
        "\n",
        "df_fb = df_fb.with_columns(pl.Series(\"out_pred_nn\", out_pred_all),\n",
        "                               pl.Series(\"single_pred_nn\", single_pred_all),\n",
        "                               pl.Series(\"double_pred_nn\", double_pred_all),\n",
        "                               pl.Series(\"triple_pred_nn\", triple_pred_all),\n",
        "                           pl.Series(\"homerun_pred_nn\", homerun_pred_all))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "U3fRRouwTNwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_fb, preds = 'out_pred_nn', actuals = 'out', model = 'Neural Net 4 Layers Fly Ball Model (Outs)')"
      ],
      "metadata": {
        "id": "SOqm8x6PmjPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_fb, preds = 'single_pred_nn', actuals = 'single', model = 'Neural Net 4 Layers Fly Ball Model (Singles)')"
      ],
      "metadata": {
        "id": "wQ3kY-YemjPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_fb, preds = 'double_pred_nn', actuals = 'double', model = 'Neural Net 4 Layers Fly Ball Model (Doubles)')"
      ],
      "metadata": {
        "id": "TiSLzoqhmjPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_fb, preds = 'triple_pred_nn', actuals = 'triple', model = 'Neural Net 4 Layers Fly Ball Model (Triples)')"
      ],
      "metadata": {
        "id": "tMMRl_1ZmjPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(data = df_fb, preds = 'homerun_pred_nn', actuals = 'home_run', model = 'Neural Net 4 Layers Fly Ball Model (Home Runs)')"
      ],
      "metadata": {
        "id": "jnh-1_4YmjPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First Model"
      ],
      "metadata": {
        "id": "h3Pop11ta57E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Swing Model"
      ],
      "metadata": {
        "id": "DiXZK73fbdDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'swing'\n",
        "\n",
        "df_pandas = df.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "model = XGBClassifier()\n",
        "preds = cross_val_predict(model, X, y , cv=5, method='predict_proba')\n",
        "\n",
        "df = df.with_columns(pl.Series(\"swing_pred_xgb\", preds[:, 1]),\n",
        "                     pl.Series(\"take_pred_xgb\", preds[:, 0]))"
      ],
      "metadata": {
        "id": "_Oy0M0kypa2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.write_csv('df_swings.csv')\n",
        "files.download('df_swings.csv')"
      ],
      "metadata": {
        "id": "8dYl2L_EfPA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Strike/Ball/HBP Model"
      ],
      "metadata": {
        "id": "8npZN-0Zc0r0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pl.read_csv('/content/drive/MyDrive/Datasets/stuff/df_swings.csv')\n",
        "\n",
        "df = df.with_columns([\n",
        "    pl.when(pl.col('called_strike') == 1)\n",
        "    .then(0)\n",
        "    .when(pl.col('called_ball') ==  1)\n",
        "    .then(1)\n",
        "    .otherwise(2)\n",
        "    .alias('take_target')\n",
        "])"
      ],
      "metadata": {
        "id": "HvbU_GKbfOWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural net 3 dense layer model\n",
        "feats = ['swing'] + ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed',\n",
        "                     'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = ['take_target']\n",
        "\n",
        "df_pandas = df.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "strike_pred_all = np.zeros(y.shape[0], dtype=float)\n",
        "ball_pred_all = np.zeros(y.shape[0], dtype=float)\n",
        "hbp_pred_all = np.zeros(y.shape[0], dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "    # Split into train/test datasets\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    # Filter train dataset to only appropriate rows\n",
        "    X_train = X_train.loc[X_train['swing'] == 0]\n",
        "    y_train = y_train.loc[X_train.index]\n",
        "\n",
        "    # Drop filter feature\n",
        "    X_train = X_train.drop(['swing'], axis = 1)\n",
        "    X_test = X_test.drop(['swing'], axis = 1)\n",
        "\n",
        "    # Train model on those rows\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape = (X_train.shape[1],)),\n",
        "        Dense(64, activation = 'relu'),\n",
        "        Dense(32, activation = 'relu'),\n",
        "        Dense(3, activation = 'softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor = 'val_loss',\n",
        "        patience = 0,\n",
        "        restore_best_weights = True,\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train, validation_split = 0.2, callbacks = [early_stop], epochs = 15, batch_size = 1024, verbose = 1)\n",
        "\n",
        "    # Make predictions on entire test dataset\n",
        "    preds = model.predict(X_test_scaled)\n",
        "\n",
        "    strike_pred_all[test_idx] = preds[:, 0]\n",
        "    ball_pred_all[test_idx] = preds[:, 1]\n",
        "    hbp_pred_all[test_idx] = preds[:, 2]\n",
        "\n",
        "\n",
        "df = df.with_columns(pl.Series(\"called_strike_pred_nn\", strike_pred_all),\n",
        "                               pl.Series(\"called_ball_pred_nn\", ball_pred_all),\n",
        "                               pl.Series(\"called_hbp_pred_nn\", hbp_pred_all))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gh5AINNrcxGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.write_csv('df_takes.csv')\n",
        "files.download('df_takes.csv')"
      ],
      "metadata": {
        "id": "gWg55A3ZrF2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Contact/Whiff Model"
      ],
      "metadata": {
        "id": "z2a_z7KJw9Cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pl.read_csv('/content/drive/MyDrive/Datasets/stuff/df_takes.csv')"
      ],
      "metadata": {
        "id": "MKl2LlSquv_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost sigmoid model\n",
        "feats = ['swing'] + ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'contact'\n",
        "\n",
        "df_pandas = df.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "contact_pred_all = np.zeros_like(y, dtype=float)\n",
        "whiff_pred_all = np.zeros_like(y, dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "    # Split into train/test datasets\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    # Filter train dataset to only appropriate rows\n",
        "    X_train = X_train.loc[X_train['swing'] == 1]\n",
        "    y_train = y_train.loc[X_train.index]\n",
        "\n",
        "    # Drop filter feature\n",
        "    X_train = X_train.drop(['swing'], axis = 1)\n",
        "    X_test = X_test.drop(['swing'], axis = 1)\n",
        "\n",
        "    # Train model on those rows\n",
        "    xgb = XGBClassifier()\n",
        "\n",
        "    calibrated_xgb = CalibratedClassifierCV(xgb, method = 'sigmoid', cv = 3)\n",
        "    calibrated_xgb.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on entire test dataset\n",
        "    preds = calibrated_xgb.predict_proba(X_test)\n",
        "\n",
        "    contact_pred_all[test_idx] = preds[:, 1]\n",
        "    whiff_pred_all[test_idx] = preds[:, 0]\n",
        "\n",
        "\n",
        "df = df.with_columns(pl.Series(\"contact_pred_xgb\", contact_pred_all),\n",
        "                               pl.Series(\"whiff_pred_xgb\", whiff_pred_all))"
      ],
      "metadata": {
        "id": "cq65zfnMxHC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.write_csv('df_contact.csv')\n",
        "files.download('df_contact.csv')"
      ],
      "metadata": {
        "id": "EcaOCtHLzO6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batted Ball Model"
      ],
      "metadata": {
        "id": "fdJbSXyc3rgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pl.read_csv('/content/drive/MyDrive/Datasets/stuff/df_contact.csv')\n",
        "\n",
        "df = df.with_columns(\n",
        "    pl.when(pl.col('bb_type') == 'foul')\n",
        "    .then(0)\n",
        "    .when(pl.col('bb_type') == 'ground_ball')\n",
        "    .then(1)\n",
        "    .when(pl.col('bb_type') == 'line_drive')\n",
        "    .then(2)\n",
        "    .when(pl.col('bb_type') == 'fly_ball')\n",
        "    .then(3)\n",
        "    .when(pl.col('bb_type') == 'popup')\n",
        "    .then(4)\n",
        "    .otherwise(5) # placeholder that will get dropped when model trains\n",
        "    .alias('bb_target')\n",
        ")"
      ],
      "metadata": {
        "id": "OxPAv4ik1NaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural net 3 layer model\n",
        "feats = ['contact'] + ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'bb_target'\n",
        "\n",
        "df_pandas = df.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "foul_pred_all = np.zeros(y.shape[0], dtype=float)\n",
        "gb_pred_all = np.zeros(y.shape[0], dtype=float)\n",
        "ld_pred_all = np.zeros(y.shape[0], dtype=float)\n",
        "fb_pred_all = np.zeros(y.shape[0], dtype=float)\n",
        "po_pred_all = np.zeros(y.shape[0], dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "    # Split into train/test datasets\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    # Filter train dataset to only appropriate rows\n",
        "    X_train = X_train.loc[X_train['contact'] == 1]\n",
        "    y_train = y_train.loc[X_train.index]\n",
        "\n",
        "    # Drop filter feature\n",
        "    X_train = X_train.drop(['contact'], axis = 1)\n",
        "    X_test = X_test.drop(['contact'], axis = 1)\n",
        "\n",
        "    # Train model on those rows\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape = (X_train.shape[1],)),\n",
        "        Dense(64, activation = 'relu'),\n",
        "        Dense(32, activation = 'relu'),\n",
        "        Dense(5, activation = 'softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor = 'val_loss',\n",
        "        patience = 0,\n",
        "        restore_best_weights = True,\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train, validation_split = 0.2, callbacks = [early_stop], epochs = 15, batch_size = 1024, verbose = 1)\n",
        "\n",
        "    # Make predictions on entire test dataset\n",
        "    preds = model.predict(X_test_scaled)\n",
        "\n",
        "    foul_pred_all[test_idx] = preds[:, 0]\n",
        "    gb_pred_all[test_idx] = preds[:, 1]\n",
        "    ld_pred_all[test_idx] = preds[:, 2]\n",
        "    fb_pred_all[test_idx] = preds[:, 3]\n",
        "    po_pred_all[test_idx] = preds[:, 4]\n",
        "\n",
        "\n",
        "df = df.with_columns(pl.Series(\"foul_pred_nn\", foul_pred_all),\n",
        "                               pl.Series(\"gb_pred_nn\", gb_pred_all),\n",
        "                               pl.Series(\"ld_pred_nn\", ld_pred_all),\n",
        "                               pl.Series(\"fb_pred_nn\", fb_pred_all),\n",
        "                               pl.Series(\"po_pred_nn\", po_pred_all))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "cfikw6H94DaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.write_csv('df_bb.csv')\n",
        "files.download('df_bb.csv')"
      ],
      "metadata": {
        "id": "PLtP7eCW5oFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ground Ball Model"
      ],
      "metadata": {
        "id": "BLydUfINKYlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pl.read_csv('/content/drive/MyDrive/Datasets/stuff/df_bb.csv')\n",
        "\n",
        "df = df.with_columns(\n",
        "    pl.when(pl.col('out') == 1)\n",
        "    .then(0)\n",
        "    .when(pl.col('single') == 1)\n",
        "    .then(1)\n",
        "    .when(pl.col('double') == 1)\n",
        "    .then(2)\n",
        "    .when(pl.col('triple') == 1)\n",
        "    .then(3)\n",
        "    .otherwise(4) # placeholder that gets dropped when filtered\n",
        "    .alias('gb_target')\n",
        ")"
      ],
      "metadata": {
        "id": "nCeAxea86SKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural net 4 layer model\n",
        "feats = ['bb_type'] + ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'gb_target'\n",
        "\n",
        "df_pandas = df.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "out_pred_all = np.zeros(y.shape[0], dtype=float)\n",
        "single_pred_all = np.zeros(y.shape[0], dtype=float)\n",
        "double_pred_all = np.zeros(y.shape[0], dtype=float)\n",
        "triple_pred_all = np.zeros(y.shape[0], dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    # Split into train/test datasets\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    # Filter train dataset to only appropriate rows\n",
        "    X_train = X_train.loc[X_train['bb_type'] == 'ground_ball']\n",
        "    y_train = y_train.loc[X_train.index]\n",
        "\n",
        "    # Drop filter feature\n",
        "    X_train = X_train.drop(['bb_type'], axis = 1)\n",
        "    X_test = X_test.drop(['bb_type'], axis = 1)\n",
        "\n",
        "    # Train model on filtered data\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape = (X_train.shape[1],)),\n",
        "        Dense(128, activation = 'relu'),\n",
        "        Dense(64, activation = 'relu'),\n",
        "        Dense(32, activation = 'relu'),\n",
        "        Dense(4, activation = 'softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor = 'val_loss',\n",
        "        patience = 0,\n",
        "        restore_best_weights = True,\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train, validation_split = 0.2, callbacks = [early_stop], epochs = 15, batch_size = 1024, verbose = 1)\n",
        "\n",
        "    # Make predictions on entire test dataset\n",
        "    preds = model.predict(X_test_scaled)\n",
        "\n",
        "    out_pred_all[test_idx] = preds[:, 0]\n",
        "    single_pred_all[test_idx] = preds[:, 1]\n",
        "    double_pred_all[test_idx] = preds[:, 2]\n",
        "    triple_pred_all[test_idx] = preds[:, 3]\n",
        "\n",
        "\n",
        "df = df.with_columns(pl.Series(\"gb_out_pred_nn\", out_pred_all),\n",
        "                               pl.Series(\"gb_single_pred_nn\", single_pred_all),\n",
        "                               pl.Series(\"gb_double_pred_nn\", double_pred_all),\n",
        "                               pl.Series(\"gb_triple_pred_nn\", triple_pred_all))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Zb9zdf_rKqE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.write_csv('df_gb.csv')\n",
        "files.download('df_gb.csv')"
      ],
      "metadata": {
        "id": "ZSu-8EG-OeKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Line Drive Model"
      ],
      "metadata": {
        "id": "ejYPjkMUVdbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pl.read_csv('/content/drive/MyDrive/Datasets/stuff/df_gb.csv')\n",
        "\n",
        "df = df.with_columns(\n",
        "    pl.when(pl.col('out') == 1)\n",
        "    .then(0)\n",
        "    .when(pl.col('single') == 1)\n",
        "    .then(1)\n",
        "    .when(pl.col('double') == 1)\n",
        "    .then(2)\n",
        "    .when(pl.col('triple') == 1)\n",
        "    .then(3)\n",
        "    .otherwise(4) # placeholder that gets dropped when filtered\n",
        "    .alias('ld_target')\n",
        ")"
      ],
      "metadata": {
        "id": "Ftwn8pPbOfm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural net 2 layer model\n",
        "feats = ['bb_type'] + ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'ld_target'\n",
        "\n",
        "df_pandas = df.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "out_pred_all = np.zeros(y.shape[0], dtype=float)\n",
        "single_pred_all = np.zeros(y.shape[0], dtype=float)\n",
        "double_pred_all = np.zeros(y.shape[0], dtype=float)\n",
        "triple_pred_all = np.zeros(y.shape[0], dtype=float)\n",
        "homerun_pred_all = np.zeros(y.shape[0], dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    # Split into train/test datasets\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    # Filter train dataset to only appropriate rows\n",
        "    X_train = X_train.loc[X_train['bb_type'] == 'line_drive']\n",
        "    y_train = y_train.loc[X_train.index]\n",
        "\n",
        "    # Drop filter feature\n",
        "    X_train = X_train.drop(['bb_type'], axis = 1)\n",
        "    X_test = X_test.drop(['bb_type'], axis = 1)\n",
        "\n",
        "    # Train model on filtered data\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape = (X_train.shape[1],)),\n",
        "        Dense(32, activation = 'relu'),\n",
        "        Dense(5, activation = 'softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor = 'val_loss',\n",
        "        patience = 0,\n",
        "        restore_best_weights = True,\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train, validation_split = 0.2, callbacks = [early_stop], epochs = 15, batch_size = 1024, verbose = 1)\n",
        "\n",
        "    # Make predictions on entire test dataset\n",
        "    preds = model.predict(X_test_scaled)\n",
        "\n",
        "    out_pred_all[test_idx] = preds[:, 0]\n",
        "    single_pred_all[test_idx] = preds[:, 1]\n",
        "    double_pred_all[test_idx] = preds[:, 2]\n",
        "    triple_pred_all[test_idx] = preds[:, 3]\n",
        "    homerun_pred_all[test_idx] = preds[:, 4]\n",
        "\n",
        "\n",
        "df = df.with_columns(pl.Series(\"ld_out_pred_nn\", out_pred_all),\n",
        "                               pl.Series(\"ld_single_pred_nn\", single_pred_all),\n",
        "                               pl.Series(\"ld_double_pred_nn\", double_pred_all),\n",
        "                               pl.Series(\"ld_triple_pred_nn\", triple_pred_all),\n",
        "                           pl.Series(\"ld_homerun_pred_nn\", homerun_pred_all))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "GCRZMvniVjFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['take_target', 'bb_target', 'gb_target', 'ld_target'])"
      ],
      "metadata": {
        "id": "TGSipRc6Zn8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.write_csv('df_ld.csv')\n",
        "files.download('df_ld.csv')"
      ],
      "metadata": {
        "id": "36XLld9CZcty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FB Model"
      ],
      "metadata": {
        "id": "ViZPmvumhwDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pl.read_csv('/content/drive/MyDrive/Datasets/stuff/df_ld.csv')\n",
        "\n",
        "df = df.with_columns(\n",
        "    pl.when(pl.col('out') == 1)\n",
        "    .then(0)\n",
        "    .when(pl.col('single') == 1)\n",
        "    .then(1)\n",
        "    .when(pl.col('double') == 1)\n",
        "    .then(2)\n",
        "    .when(pl.col('triple') == 1)\n",
        "    .then(3)\n",
        "    .otherwise(4) # placeholder that gets dropped when filtered\n",
        "    .alias('fb_target')\n",
        ")"
      ],
      "metadata": {
        "id": "k1FPOGABdPEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural net 2 layer model\n",
        "feats = ['bb_type'] + ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'fb_target'\n",
        "\n",
        "df_pandas = df.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "out_pred_all = np.zeros(y.shape[0], dtype=float)\n",
        "single_pred_all = np.zeros(y.shape[0], dtype=float)\n",
        "double_pred_all = np.zeros(y.shape[0], dtype=float)\n",
        "triple_pred_all = np.zeros(y.shape[0], dtype=float)\n",
        "homerun_pred_all = np.zeros(y.shape[0], dtype=float)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    # Split into train/test datasets\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    # Filter train dataset to only appropriate rows\n",
        "    X_train = X_train.loc[X_train['bb_type'] == 'fly_ball']\n",
        "    y_train = y_train.loc[X_train.index]\n",
        "\n",
        "    # Drop filter feature\n",
        "    X_train = X_train.drop(['bb_type'], axis = 1)\n",
        "    X_test = X_test.drop(['bb_type'], axis = 1)\n",
        "\n",
        "    # Train model on filtered data\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape = (X_train.shape[1],)),\n",
        "        Dense(32, activation = 'relu'),\n",
        "        Dense(5, activation = 'softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor = 'val_loss',\n",
        "        patience = 1,\n",
        "        restore_best_weights = True,\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train, validation_split = 0.2, callbacks = [early_stop], epochs = 15, batch_size = 64, verbose = 1)\n",
        "\n",
        "    # Make predictions on entire dataset\n",
        "    preds = model.predict(X_test_scaled)\n",
        "\n",
        "    out_pred_all[test_idx] = preds[:, 0]\n",
        "    single_pred_all[test_idx] = preds[:, 1]\n",
        "    double_pred_all[test_idx] = preds[:, 2]\n",
        "    triple_pred_all[test_idx] = preds[:, 3]\n",
        "    homerun_pred_all[test_idx] = preds[:, 4]\n",
        "\n",
        "\n",
        "df = df.with_columns(pl.Series(\"fb_out_pred_nn\", out_pred_all),\n",
        "                               pl.Series(\"fb_single_pred_nn\", single_pred_all),\n",
        "                               pl.Series(\"fb_double_pred_nn\", double_pred_all),\n",
        "                               pl.Series(\"fb_triple_pred_nn\", triple_pred_all),\n",
        "                           pl.Series(\"fb_homerun_pred_nn\", homerun_pred_all))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "AIIxWJDrh32X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RV Preds"
      ],
      "metadata": {
        "id": "xQisR0V3pKos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting mean rv for each event\n",
        "called_strike = df.filter(pl.col('called_strike') == 1)['delta_run_exp'].mean()\n",
        "called_ball = df.filter(pl.col('called_ball') == 1)['delta_run_exp'].mean()\n",
        "called_hbp = df.filter(pl.col('called_hbp') == 1)['delta_run_exp'].mean()\n",
        "\n",
        "whiff = df.filter(pl.col('whiff') == 1)['delta_run_exp'].mean()\n",
        "\n",
        "foul = df.filter(pl.col('foul') == 1)['delta_run_exp'].mean()\n",
        "popup = df.filter(pl.col('bb_type') == 'popup')['delta_run_exp'].mean()\n",
        "\n",
        "gb_out = df.filter((pl.col('bb_type') == 'ground_ball') & (pl.col('out') == 1))['delta_run_exp'].mean()\n",
        "gb_single = df.filter((pl.col('bb_type') == 'ground_ball') & (pl.col('single') == 1))['delta_run_exp'].mean()\n",
        "gb_double = df.filter((pl.col('bb_type') == 'ground_ball') & (pl.col('double') == 1))['delta_run_exp'].mean()\n",
        "gb_triple = df.filter((pl.col('bb_type') == 'ground_ball') & (pl.col('triple') == 1))['delta_run_exp'].mean()\n",
        "\n",
        "ld_out = df.filter((pl.col('bb_type') == 'line_drive') & (pl.col('out') == 1))['delta_run_exp'].mean()\n",
        "ld_single = df.filter((pl.col('bb_type') == 'line_drive') & (pl.col('single') == 1))['delta_run_exp'].mean()\n",
        "ld_double = df.filter((pl.col('bb_type') == 'line_drive') & (pl.col('double') == 1))['delta_run_exp'].mean()\n",
        "ld_triple = df.filter((pl.col('bb_type') == 'line_drive') & (pl.col('triple') == 1))['delta_run_exp'].mean()\n",
        "ld_homerun = df.filter((pl.col('bb_type') == 'line_drive') & (pl.col('home_run') == 1))['delta_run_exp'].mean()\n",
        "\n",
        "fb_out = df.filter((pl.col('bb_type') == 'fly_ball') & (pl.col('out') == 1))['delta_run_exp'].mean()\n",
        "fb_single = df.filter((pl.col('bb_type') == 'fly_ball') & (pl.col('single') == 1))['delta_run_exp'].mean()\n",
        "fb_double = df.filter((pl.col('bb_type') == 'fly_ball') & (pl.col('double') == 1))['delta_run_exp'].mean()\n",
        "fb_homerun = df.filter((pl.col('bb_type') == 'fly_ball') & (pl.col('home_run') == 1))['delta_run_exp'].mean()"
      ],
      "metadata": {
        "id": "1ybmB59jpCdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generating rv preds\n",
        "df = df.with_columns(\n",
        "    xRV_model1 = pl.col('take_pred_xgb')*pl.col('called_strike_pred_nn')*called_strike +\n",
        "    pl.col('take_pred_xgb')*pl.col('called_ball_pred_nn')*called_ball +\n",
        "    pl.col('take_pred_xgb')*pl.col('called_hbp_pred_nn')*called_hbp +\n",
        "\n",
        "    pl.col('swing_pred_xgb')*pl.col('whiff_pred_xgb')*whiff +\n",
        "\n",
        "    pl.col('swing_pred_xgb')*pl.col('contact_pred_xgb')*pl.col('foul_pred_nn')*foul +\n",
        "    pl.col('swing_pred_xgb')*pl.col('contact_pred_xgb')*pl.col('po_pred_nn')*popup +\n",
        "\n",
        "    pl.col('swing_pred_xgb')*pl.col('contact_pred_xgb')*pl.col('gb_pred_nn')*pl.col('gb_out_pred_nn')*gb_out +\n",
        "    pl.col('swing_pred_xgb')*pl.col('contact_pred_xgb')*pl.col('gb_pred_nn')*pl.col('gb_single_pred_nn')*gb_single +\n",
        "    pl.col('swing_pred_xgb')*pl.col('contact_pred_xgb')*pl.col('gb_pred_nn')*pl.col('gb_double_pred_nn')*gb_double +\n",
        "    pl.col('swing_pred_xgb')*pl.col('contact_pred_xgb')*pl.col('gb_pred_nn')*pl.col('gb_triple_pred_nn')*gb_triple +\n",
        "\n",
        "    pl.col('swing_pred_xgb')*pl.col('contact_pred_xgb')*pl.col('ld_pred_nn')*pl.col('ld_out_pred_nn')*ld_out +\n",
        "    pl.col('swing_pred_xgb')*pl.col('contact_pred_xgb')*pl.col('ld_pred_nn')*pl.col('ld_single_pred_nn')*ld_single +\n",
        "    pl.col('swing_pred_xgb')*pl.col('contact_pred_xgb')*pl.col('ld_pred_nn')*pl.col('ld_double_pred_nn')*ld_double +\n",
        "    pl.col('swing_pred_xgb')*pl.col('contact_pred_xgb')*pl.col('ld_pred_nn')*pl.col('ld_triple_pred_nn')*ld_triple +\n",
        "    pl.col('swing_pred_xgb')*pl.col('contact_pred_xgb')*pl.col('ld_pred_nn')*pl.col('ld_homerun_pred_nn')*ld_homerun +\n",
        "\n",
        "    pl.col('swing_pred_xgb')*pl.col('contact_pred_xgb')*pl.col('fb_pred_nn')*pl.col('fb_out_pred_nn')*fb_out +\n",
        "    pl.col('swing_pred_xgb')*pl.col('contact_pred_xgb')*pl.col('fb_pred_nn')*pl.col('fb_single_pred_nn')*fb_single +\n",
        "    pl.col('swing_pred_xgb')*pl.col('contact_pred_xgb')*pl.col('fb_pred_nn')*pl.col('fb_double_pred_nn')*fb_double +\n",
        "    pl.col('swing_pred_xgb')*pl.col('contact_pred_xgb')*pl.col('fb_pred_nn')*pl.col('fb_triple_pred_nn')*fb_triple +\n",
        "    pl.col('swing_pred_xgb')*pl.col('contact_pred_xgb')*pl.col('fb_pred_nn')*pl.col('fb_homerun_pred_nn')*fb_homerun\n",
        ")"
      ],
      "metadata": {
        "id": "7aYXufqaqzir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.write_csv('df_model1.csv')\n",
        "files.download('df_model1.csv')"
      ],
      "metadata": {
        "id": "meHdUEaqtrrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_valid(metric = 'xRV_model1', model = 'Ensemble Model 1')"
      ],
      "metadata": {
        "id": "U5BVp2RJskVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(df.select(pl.col('xRV_model1')))\n",
        "plt.xlim([-0.05, 0.05])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8pZbYaqcskVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best by year\n",
        "df.group_by(pl.col('game_year'), pl.col('player_name')).agg(pl.col('xRV_model1').mean()).sort('xRV_model1', descending = False).head(10)"
      ],
      "metadata": {
        "id": "e0uX1n8zskVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best by yearly pitch\n",
        " (df.with_columns([\n",
        "        pl.len().over([\"player_name\", \"pitch_type\"]).alias(\"pitch_count\")\n",
        "    ])\n",
        "    .filter(pl.col(\"pitch_count\") >= 100)\n",
        "    .group_by(pl.col('game_year'), pl.col('player_name'), pl.col('pitch_type'))\n",
        "    .agg(pl.col('xRV_model1').mean())\n",
        "    .sort('xRV_model1', descending = False).head(10)\n",
        ")"
      ],
      "metadata": {
        "id": "AYvzgZsoskVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayes Launch Angle"
      ],
      "metadata": {
        "id": "AXnwq9LNbFiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pl.read_csv('/content/drive/MyDrive/Datasets/stuff/df_model1.csv')"
      ],
      "metadata": {
        "id": "Gop6qezH09io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop unused data\n",
        "drop = ['popup', 'fb_pred_nn', 'fb_single_pred_nn', 'stand', 'api_break_x_arm', 'gb_triple_pred_nn', 'called_ball', 'sz_top', 'gb_double_pred_nn',\n",
        "    'home_run', 'fb_double_pred_nn', 'delta_home_win_exp', 'ld_triple_pred_nn', 'fly_ball', 'events', 'balls', 'gb_out_pred_nn', 'ld_pred_nn', 'adj_vx0',\n",
        "    'ld_homerun_pred_nn', 'out', 'batter', 'whiff', 'api_break_z_with_gravity', 'p_throws', 'ld_double_pred_nn', 'vz0', 'called_hbp', 'swing', 'pitcher',\n",
        "    'primary_fb_speed', 'fb_out_pred_nn', 'game_date', 'estimated_woba_using_speedangle', 'ground_ball', 'line_drive', 'triple', 'ld_out_pred_nn', 'bb_type',\n",
        "    'foul_pred_nn', 'primary_fb_horz', 'po_pred_nn', 'vy0', 'plate_z', 'plate_x', 'primary_fb_vert',\n",
        "    'double', 'gb_pred_nn', 'strikes', 'woba_value', 'gb_single_pred_nn', 'fb_homerun_pred_nn', 'single', 'sz_bot',\n",
        "    'ld_single_pred_nn', 'fb_triple_pred_nn', 'called_strike', 'fb_target', 'vx0']\n",
        "\n",
        "# filter to 2023-2024\n",
        "df_bayes = df.drop(drop).filter(pl.col('game_year').is_in([2023, 2024]))\n",
        "# filter to pitches thrown >750 times in a season by a pitcher\n",
        "df_qual = df_bayes.group_by(['game_year', 'player_name', 'pitch_type']).len().filter(pl.col('len') > 750).drop('len')\n",
        "df_bayes = df_bayes.join(df_qual, on = ['game_year', 'player_name', 'pitch_type'], how = 'inner')"
      ],
      "metadata": {
        "id": "L-PmrRwYzLZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bayes.shape"
      ],
      "metadata": {
        "id": "Jx3eoVD8ug9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bayes.write_csv('df_bayes.csv')\n",
        "files.download('df_bayes.csv')"
      ],
      "metadata": {
        "id": "1gU-0kFuzMdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bayes = pl.read_csv('/content/drive/MyDrive/Datasets/stuff/df_bayes.csv')"
      ],
      "metadata": {
        "id": "vqmSLseoixYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filter to relevant rows\n",
        "df_bip = df_bayes.filter(pl.col('description') == 'hit_into_play')\n",
        "df_bip = df_bip.with_row_index()"
      ],
      "metadata": {
        "id": "gY0PnI6o-7u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample dfs for faster plotting\n",
        "df_bip_r = df_bip.filter(pl.col('righty') == 1).sample(10000)\n",
        "df_bip_l = df_bip.filter(pl.col('righty') == 0).sample(10000)\n",
        "\n",
        "feats = ['release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed',\n",
        "         'release_spin_rate', 'spin_axis', 'pfx_x', 'ax', 'pfx_z', 'az']\n",
        "\n",
        "# correlation plots for potential feats\n",
        "for feat in feats:\n",
        "    fig, (ax1,ax2) = plt.subplots(1,2, figsize=(12,4))\n",
        "\n",
        "    sns.regplot(x = df_bip_r[feat], y = df_bip_r['launch_angle'], ax = ax1)\n",
        "    corr_r = round(df_bip_r.select(pl.corr(feat, 'launch_angle', method = 'pearson')).item(), 4)\n",
        "    ax1.set_title(f'Righties {feat} vs launch angle \\nCorr: {corr_r}')\n",
        "    ax1.set_ylim([-110, 110])\n",
        "\n",
        "    sns.regplot(x = df_bip_l[feat], y = df_bip_l['launch_angle'], ax = ax2)\n",
        "    corr_l = round(df_bip_l.select(pl.corr(feat, 'launch_angle', method = 'pearson')).item(), 4)\n",
        "    ax2.set_title(f'Lefties {feat} vs launch angle \\nCorr: {corr_l}')\n",
        "    ax2.set_ylim([-110, 110])\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "vPZc0iuIci3i",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(df_bip['launch_angle'], bins = 30)"
      ],
      "metadata": {
        "id": "gl2KSe0RrrFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Just Vert"
      ],
      "metadata": {
        "id": "Dq0sv6_bAkqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variables\n",
        "obs_id = np.arange(len(df_bip))\n",
        "X_data = df_bip.select('pfx_z').to_numpy().flatten()\n",
        "launch_angle = df_bip.select('launch_angle').to_numpy().flatten()\n",
        "\n",
        "coords = {'obs_id': obs_id}\n",
        "coords['metric'] = 'launch_angle'\n",
        "\n",
        "with pm.Model(coords = coords) as model_la:\n",
        "\n",
        "    # Priors\n",
        "    alpha = pm.Normal(\"alpha\", mu=10, sigma=10)\n",
        "    beta = pm.Normal(\"beta\", mu=2.5, sigma=10)\n",
        "    sigma = pm.HalfNormal(\"sigma\", sigma=15)\n",
        "\n",
        "    # Expected value\n",
        "    mu = alpha + beta * X_data\n",
        "\n",
        "    # Likelihood\n",
        "    y_obs = pm.Normal(\"y_obs\", mu=mu, sigma=sigma, observed=launch_angle, dims=\"obs_id\")"
      ],
      "metadata": {
        "id": "A0ayXDSlrCxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pm.model_to_graphviz(model_la)"
      ],
      "metadata": {
        "id": "i9Sjb2Y9rDxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with model_la:\n",
        "    # Prior predictive check\n",
        "    model_la_trace = pm.sample_prior_predictive(samples = 100)"
      ],
      "metadata": {
        "id": "IzTgvVsDZ3DE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(model_la_trace.prior['beta'].squeeze(), bins = 20)\n",
        "plt.xlabel('Launch Angle Beta')\n",
        "plt.title('Launch Angle Beta Prior Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4raneATh-qeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "az.plot_ppc(model_la_trace, group='prior')"
      ],
      "metadata": {
        "id": "9gR2HN4Hjvv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(model_la_trace.prior_predictive['y_obs'].squeeze().values.flatten(), bins = 135)\n",
        "plt.xlabel('Launch Angle')\n",
        "plt.title('Launch Angle Prior Predictive Distribution')\n",
        "plt.xlim([-100, 100])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8BG6BLVbE5a5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inference\n",
        "with model_la:\n",
        "    trace = pm.sample(draws=1000, tune=1000, cores=4, chains=4, random_seed=42)"
      ],
      "metadata": {
        "id": "fHqvuCULrDul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "az.summary(trace).sort_values('r_hat', ascending=False).head()"
      ],
      "metadata": {
        "id": "cbqPXsflrDrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_la_trace.extend(trace)"
      ],
      "metadata": {
        "id": "7GAdAk7xFpRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(model_la_trace.posterior['beta'].squeeze().values.flatten(), bins = 15)\n",
        "plt.xlabel('Launch Angle Beta')\n",
        "plt.title('Launch Angle Beta Posterior Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "px8u-kQrkFi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "az.plot_trace(model_la_trace, var_names = 'beta')"
      ],
      "metadata": {
        "id": "rZXbF1rXi7bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# posterior preds\n",
        "with model_la:\n",
        "    posterior_predictive = pm.sample_posterior_predictive(model_la_trace, extend_inferencedata=True)"
      ],
      "metadata": {
        "id": "jswcDjNlrDoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Datasets/stuff/model_la_trace.pkl', 'wb') as file:\n",
        "    pickle.dump(model_la_trace, file)"
      ],
      "metadata": {
        "id": "hv6st9x_rPkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Datasets/stuff/model_la_trace.pkl', 'rb') as f:\n",
        "    model_la_trace = pickle.load(f)"
      ],
      "metadata": {
        "id": "DfE7rnYCrPgP",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "az.plot_ppc(posterior_predictive, group='posterior')"
      ],
      "metadata": {
        "id": "bbMkB-9mjG-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with model_la:\n",
        "    pm.compute_log_likelihood(model_la_trace)\n",
        "\n",
        "az.loo(model_la_trace, model_la)"
      ],
      "metadata": {
        "id": "rdfjHIsvrPUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple Variables"
      ],
      "metadata": {
        "id": "YnqajstSAniq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variables\n",
        "obs_id = np.arange(len(df_bip))\n",
        "df_bip = df_bip.with_columns(\n",
        "    pfx_z_norm = (pl.col('pfx_z') - pl.col('pfx_z').mean())/pl.col('pfx_z').std(),\n",
        "    adj_pfx_x_norm = (pl.col('adj_pfx_x') - pl.col('adj_pfx_x').mean())/pl.col('adj_pfx_x').std(),\n",
        "    release_spin_rate_norm = (pl.col('release_spin_rate') - pl.col('release_spin_rate').mean())/pl.col('release_spin_rate').std()\n",
        ")\n",
        "pfx_z_norm = df_bip.select('pfx_z_norm').to_numpy().flatten()\n",
        "adj_pfx_x_norm = df_bip.select('adj_pfx_x_norm').to_numpy().flatten()\n",
        "release_spin_rate_norm = df_bip.select('release_spin_rate_norm').to_numpy().flatten()\n",
        "launch_angle = df_bip.select('launch_angle').to_numpy().flatten()\n",
        "\n",
        "coords = {'obs_id': obs_id}\n",
        "\n",
        "with pm.Model(coords = coords) as model_la2:\n",
        "\n",
        "    # Priors\n",
        "    alpha = pm.Normal(\"alpha\", mu=5, sigma=5)\n",
        "    beta_pfx_z_norm = pm.Normal(\"beta_pfx_z_norm\", mu=0, sigma=10)\n",
        "    beta_adj_pfx_x_norm = pm.Normal(\"beta_adj_pfx_x_norm\", mu=5, sigma=10)\n",
        "    beta_release_spin_rate_norm = pm.Normal(\"beta_release_spin_rate_norm\", mu=0, sigma=10)\n",
        "    sigma = pm.HalfNormal(\"sigma\", sigma=3)\n",
        "\n",
        "    # Expected value\n",
        "    mu = alpha + beta_pfx_z_norm*pfx_z_norm + beta_adj_pfx_x_norm*adj_pfx_x_norm + beta_release_spin_rate_norm*release_spin_rate_norm\n",
        "    # Likelihood\n",
        "    y_obs = pm.Normal(\"y_obs\", mu=mu, sigma=sigma, observed=launch_angle, dims=\"obs_id\")"
      ],
      "metadata": {
        "id": "1Y8mj7lsAqX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pm.model_to_graphviz(model_la2)"
      ],
      "metadata": {
        "id": "VwenOhCNAqU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with model_la2:\n",
        "    # Prior predictive check\n",
        "    model_la2_trace = pm.sample_prior_predictive(samples = 100)"
      ],
      "metadata": {
        "id": "wmVHRxAzIbBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(model_la2_trace.prior_predictive['y_obs'].squeeze().values.flatten())\n",
        "plt.xlabel('Launch Angle')\n",
        "plt.title('Launch Angle Prior Predictive Distribution')\n",
        "plt.xlim([-100, 100])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S70alUCgIbBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inference\n",
        "with model_la2:\n",
        "    trace = pm.sample(draws=1000, tune=1000, cores=4, chains=4, random_seed=42)"
      ],
      "metadata": {
        "id": "aFCTAVqRK-wV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "az.summary(trace).sort_values('r_hat', ascending=False).head()"
      ],
      "metadata": {
        "id": "MSMRGaqxK-wW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_la2_trace.extend(trace)"
      ],
      "metadata": {
        "id": "sQN8KJbRK-wW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "az.plot_trace(model_la2_trace, var_names = ['beta_adj_pfx_x_norm', 'beta_pfx_z_norm', 'beta_release_spin_rate_norm'], figsize=(12, 10))"
      ],
      "metadata": {
        "id": "QGLwnVbDK-wW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# posterior predictive\n",
        "with model_la2:\n",
        "    posterior_predictive = pm.sample_posterior_predictive(model_la2_trace, extend_inferencedata=True)"
      ],
      "metadata": {
        "id": "-1P7NOjh111c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "az.plot_ppc(posterior_predictive, group='posterior')"
      ],
      "metadata": {
        "id": "n9QLsGL1111d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with model_la2:\n",
        "    pm.compute_log_likelihood(model_la2_trace)\n",
        "\n",
        "az.loo(model_la2_trace, model_la2)"
      ],
      "metadata": {
        "id": "x7OZFKco111d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preds"
      ],
      "metadata": {
        "id": "XonLNHMULxhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_cols = [\"pfx_z\", \"adj_pfx_x\", \"release_spin_rate\", 'description']\n",
        "y_col = \"launch_angle\"\n",
        "\n",
        "X = df_bayes.select(X_cols)\n",
        "y = df_bayes.select(y_col)\n",
        "\n",
        "# To pandas\n",
        "X = X.to_pandas()\n",
        "y = y.to_pandas()\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "xLA_25_all = np.zeros(y.shape[0])\n",
        "xLA_50_all = np.zeros(y.shape[0])\n",
        "xLA_75_all = np.zeros(y.shape[0])\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    # Create train/test splits\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    # Filter train data to BIP\n",
        "    X_train = X_train.loc[X_train['description'] == 'hit_into_play']\n",
        "    y_train = y_train.loc[y_train.index.isin(X_train.index)]\n",
        "\n",
        "    # Drop filter feature\n",
        "    X_train = X_train.drop(['description'], axis = 1)\n",
        "    X_test = X_test.drop(['description'], axis = 1)\n",
        "\n",
        "    # To polars\n",
        "    X_train = pl.DataFrame(X_train)\n",
        "    X_test = pl.DataFrame(X_test)\n",
        "    y_train = pl.DataFrame(y_train)\n",
        "    y_test = pl.DataFrame(y_test)\n",
        "\n",
        "    # Train Variables\n",
        "    pfx_z_mean_train = X_train.select('pfx_z').mean().item()\n",
        "    pfx_z_std_train = X_train.select('pfx_z').std().item()\n",
        "    adj_pfx_x_mean_train = X_train.select('adj_pfx_x').mean().item()\n",
        "    adj_pfx_x_std_train = X_train.select('adj_pfx_x').std().item()\n",
        "    release_spin_rate_mean_train = X_train.select('release_spin_rate').mean().item()\n",
        "    release_spin_rate_std_train = X_train.select('release_spin_rate').std().item()\n",
        "\n",
        "    X_train = X_train.with_columns(\n",
        "        pfx_z_norm = (pl.col('pfx_z') - pl.col('pfx_z').mean())/pl.col('pfx_z').std(),\n",
        "        adj_pfx_x_norm = (pl.col('adj_pfx_x') - pl.col('adj_pfx_x').mean())/pl.col('adj_pfx_x').std(),\n",
        "        release_spin_rate_norm = (pl.col('release_spin_rate') - pl.col('release_spin_rate').mean())/pl.col('release_spin_rate').std()\n",
        "    )\n",
        "    pfx_z_norm_train = X_train.select('pfx_z_norm').to_numpy().flatten()\n",
        "    adj_pfx_x_norm_train = X_train.select('adj_pfx_x_norm').to_numpy().flatten()\n",
        "    release_spin_rate_norm_train = X_train.select('release_spin_rate_norm').to_numpy().flatten()\n",
        "    launch_angle_train = y_train.to_numpy().flatten()\n",
        "\n",
        "    # Test Variables\n",
        "    X_test = X_test.with_columns(\n",
        "        pfx_z_norm = (pl.col('pfx_z') - pfx_z_mean_train)/pfx_z_std_train,\n",
        "        adj_pfx_x_norm = (pl.col('adj_pfx_x') - adj_pfx_x_mean_train)/adj_pfx_x_std_train,\n",
        "        release_spin_rate_norm = (pl.col('release_spin_rate') - release_spin_rate_mean_train)/release_spin_rate_std_train\n",
        "    )\n",
        "    pfx_z_norm_test = X_test.select('pfx_z_norm').to_numpy().flatten()\n",
        "    adj_pfx_x_norm_test = X_test.select('adj_pfx_x_norm').to_numpy().flatten()\n",
        "    release_spin_rate_norm_test = X_test.select('release_spin_rate_norm').to_numpy().flatten()\n",
        "    launch_angle_test = y_test.to_numpy().flatten()\n",
        "\n",
        "\n",
        "    with pm.Model() as model_la_pred:\n",
        "        # Declare data\n",
        "        pfx_z_norm = pm.Data('pfx_z_norm', pfx_z_norm_train)\n",
        "        adj_pfx_x_norm = pm.Data('adj_pfx_x_norm', adj_pfx_x_norm_train)\n",
        "        release_spin_rate_norm = pm.Data('release_spin_rate_norm', release_spin_rate_norm_train)\n",
        "        launch_angle = pm.Data('launch_angle', launch_angle_train)\n",
        "\n",
        "        # Priors\n",
        "        alpha = pm.Normal(\"alpha\", mu=5, sigma=5)\n",
        "        beta_pfx_z_norm = pm.Normal(\"beta_pfx_z_norm\", mu=0, sigma=10)\n",
        "        beta_adj_pfx_x_norm = pm.Normal(\"beta_adj_pfx_x_norm\", mu=5, sigma=10)\n",
        "        beta_release_spin_rate_norm = pm.Normal(\"beta_release_spin_rate_norm\", mu=0, sigma=10)\n",
        "        sigma = pm.HalfNormal(\"sigma\", sigma=3)\n",
        "\n",
        "        # Expected value\n",
        "        mu = alpha + beta_pfx_z_norm*pfx_z_norm + beta_adj_pfx_x_norm*adj_pfx_x_norm + beta_release_spin_rate_norm*release_spin_rate_norm\n",
        "        # Likelihood\n",
        "        y_obs = pm.Normal(\"y_obs\", mu=mu, sigma=sigma, observed=launch_angle)\n",
        "\n",
        "        # Sample posterior\n",
        "        trace = pm.sample(1000, tune=1000, cores=4, chains=4, random_seed=42)\n",
        "\n",
        "        # Predict on test set\n",
        "        pm.set_data({\n",
        "        \"pfx_z_norm\": pfx_z_norm_test,\n",
        "        \"adj_pfx_x_norm\": adj_pfx_x_norm_test,\n",
        "        \"release_spin_rate_norm\": release_spin_rate_norm_test,\n",
        "        'launch_angle': launch_angle_test\n",
        "        })\n",
        "\n",
        "        posterior_predictive = pm.sample_posterior_predictive(trace, model = model_la_pred, var_names = ['y_obs'])\n",
        "\n",
        "        # Get percentiles\n",
        "        y_pred_samples = posterior_predictive.posterior_predictive[\"y_obs\"]\n",
        "        n_y_obs = y_pred_samples.shape[-1]\n",
        "        flat_samples = y_pred_samples.values.reshape(-1, n_y_obs)\n",
        "\n",
        "        percentiles = np.percentile(flat_samples, [25, 50, 75], axis=0)\n",
        "        xLA_25_all[test_idx] = percentiles[0]\n",
        "        xLA_50_all[test_idx] = percentiles[1]\n",
        "        xLA_75_all[test_idx] = percentiles[2]"
      ],
      "metadata": {
        "id": "5uwJuWmEAp8u",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bayes = df_bayes.with_columns(pl.Series(\"xLA_25\", xLA_25_all),\n",
        "                               pl.Series(\"xLA_50\", xLA_50_all),\n",
        "                               pl.Series(\"xLA_75\", xLA_75_all))"
      ],
      "metadata": {
        "id": "4eGRdL1Ir8oO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bayes.head()"
      ],
      "metadata": {
        "id": "zqZ2e-svtlsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bayes.write_csv('df_bayes_la.csv')\n",
        "files.download('df_bayes_la.csv')"
      ],
      "metadata": {
        "id": "QAxHhFsmuDeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayes Exit Velo"
      ],
      "metadata": {
        "id": "8DlFaU-pnj-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_bayes_la = pl.read_csv('/content/drive/MyDrive/Datasets/stuff/df_bayes_la.csv')"
      ],
      "metadata": {
        "id": "Zdy7zYkOwJDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filter to relevant rows\n",
        "df_bip = df_bayes_la.filter(pl.col('description') == 'hit_into_play')\n",
        "df_bip = df_bip.with_row_index()"
      ],
      "metadata": {
        "id": "7JOPo5at2joc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample dfs for faster plotting\n",
        "df_bip_r = df_bip.filter(pl.col('p_throws') == 'R').sample(10000)\n",
        "df_bip_l = df_bip.filter(pl.col('p_throws') == 'L').sample(10000)\n",
        "\n",
        "feats = ['release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed',\n",
        "         'release_spin_rate', 'spin_axis', 'pfx_x', 'ax', 'pfx_z', 'az']\n",
        "\n",
        "# corr plots for potential feats\n",
        "for feat in feats:\n",
        "    fig, (ax1,ax2) = plt.subplots(1,2, figsize=(12,4))\n",
        "\n",
        "    sns.regplot(x = df_bip_r[feat], y = df_bip_r['launch_speed'], ax = ax1)\n",
        "    corr_r = round(df_bip_r.select(pl.corr(feat, 'launch_speed', method = 'pearson')).item(), 4)\n",
        "    ax1.set_title(f'Righties {feat} vs exit velocity \\nCorr: {corr_r}')\n",
        "    ax1.set_ylim([5, 125])\n",
        "\n",
        "    sns.regplot(x = df_bip_l[feat], y = df_bip_l['launch_speed'], ax = ax2)\n",
        "    corr_l = round(df_bip_l.select(pl.corr(feat, 'launch_speed', method = 'pearson')).item(), 4)\n",
        "    ax2.set_title(f'Lefties {feat} vs exit velocity \\nCorr: {corr_l}')\n",
        "    ax2.set_ylim([5, 125])\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "LMoDWRivfl0Y",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Just Velo"
      ],
      "metadata": {
        "id": "BHXgufuw3ALm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(df_bip['launch_speed'])\n",
        "plt.title('Exit Velo Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kBvTlEdv3qbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variables\n",
        "df_bip = df_bip.with_columns(\n",
        "    release_speed_norm = (pl.col('release_speed') - pl.col('release_speed').mean())/pl.col('release_speed').std()\n",
        ")\n",
        "release_speed_norm = df_bip.select('release_speed_norm').to_numpy().flatten()\n",
        "launch_speed = df_bip.select('launch_speed').to_numpy().flatten()\n",
        "\n",
        "with pm.Model() as model_ev:\n",
        "\n",
        "    # Priors\n",
        "    theta = pm.Normal('theta', mu = 80, sigma = 10)\n",
        "    beta = pm.Normal(\"beta\", mu = 5, sigma = 10)\n",
        "    alpha = pm.Normal(\"alpha\", mu = -6, sigma = 3)\n",
        "    sigma = pm.HalfNormal(\"sigma\", sigma=0.75)\n",
        "\n",
        "    # Expected value\n",
        "    mu = theta + beta * release_speed_norm\n",
        "\n",
        "    # Likelihood\n",
        "    y_obs = pm.SkewNormal(\"y_obs\", mu=mu, sigma=sigma, alpha = alpha, observed=launch_speed)"
      ],
      "metadata": {
        "id": "afT84eAe3BM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pm.model_to_graphviz(model_ev)"
      ],
      "metadata": {
        "id": "TlmkzWTM3BM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with model_ev:\n",
        "    # Prior predictive check\n",
        "    model_ev_trace = pm.sample_prior_predictive(samples = 100)"
      ],
      "metadata": {
        "id": "q9tmyJgb3BM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "az.plot_ppc(model_ev_trace, group='prior')"
      ],
      "metadata": {
        "id": "L4Rxde9p3BM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(model_ev_trace.prior_predictive['y_obs'].squeeze().values.flatten(), bins = 135)\n",
        "plt.xlabel('Exit Velo')\n",
        "plt.title('Exit Velo Prior Predictive Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mSVGB7RR3BM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inference\n",
        "with model_ev:\n",
        "    trace = pm.sample(draws=1000, tune=1000, cores=4, chains=4, random_seed=42)"
      ],
      "metadata": {
        "id": "QMkrQgzM3BM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "az.summary(trace).sort_values('r_hat', ascending=False).head()"
      ],
      "metadata": {
        "id": "1vFrHBLo3BM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ev_trace.extend(trace)"
      ],
      "metadata": {
        "id": "GQsik8H13BM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "az.plot_trace(model_ev_trace, var_names = ['alpha', 'beta', 'sigma', 'theta'], figsize=(12, 10))"
      ],
      "metadata": {
        "id": "dTol83-13BM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# posterior predictive\n",
        "with model_ev:\n",
        "    posterior_predictive_ev = pm.sample_posterior_predictive(model_ev_trace, extend_inferencedata=True)"
      ],
      "metadata": {
        "id": "8kiHmEvS3BM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Datasets/stuff/model_ev_trace.pkl', 'wb') as file:\n",
        "    pickle.dump(posterior_predictive_ev, file)"
      ],
      "metadata": {
        "id": "5pL72_Ig3BM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Datasets/stuff/model_ev_trace.pkl', 'rb') as f:\n",
        "    posterior_predictive_ev = pickle.load(f)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "B9dYoalC3BM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "az.plot_ppc(posterior_predictive_ev, group='posterior')"
      ],
      "metadata": {
        "id": "aygJPDu63BM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with model_ev:\n",
        "    pm.compute_log_likelihood(model_ev_trace)\n",
        "\n",
        "az.loo(model_ev_trace, model_ev)"
      ],
      "metadata": {
        "id": "rPEjS8Ve3BM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## More Variables"
      ],
      "metadata": {
        "id": "2P7aKGv9MZwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variables\n",
        "df_bip = df_bip.with_columns(\n",
        "    release_speed_norm = (pl.col('release_speed') - pl.col('release_speed').mean())/pl.col('release_speed').std(),\n",
        "    adj_ax_norm = (pl.col('adj_ax') - pl.col('adj_ax').mean())/pl.col('adj_ax').std(),\n",
        "    az_norm = (pl.col('az') - pl.col('az').mean())/pl.col('az').std()\n",
        ")\n",
        "release_speed_norm = df_bip.select('release_speed_norm').to_numpy().flatten()\n",
        "adj_ax_norm = df_bip.select('adj_ax_norm').to_numpy().flatten()\n",
        "az_norm = df_bip.select('az_norm').to_numpy().flatten()\n",
        "launch_speed = df_bip.select('launch_speed').to_numpy().flatten()\n",
        "\n",
        "with pm.Model() as model_ev2:\n",
        "\n",
        "    # Priors\n",
        "    theta = pm.Normal('theta', mu = 80, sigma = 10)\n",
        "    beta_release_speed_norm = pm.Normal(\"beta_release_speed_norm\", mu = 5, sigma = 10)\n",
        "    beta_adj_ax_norm = pm.Normal(\"beta_adj_ax_norm\", mu = -5, sigma = 10)\n",
        "    beta_az_norm = pm.Normal(\"beta_az_norm\", mu = 5, sigma = 10)\n",
        "    alpha = pm.Normal(\"alpha\", mu = -6, sigma = 3)\n",
        "    sigma = pm.HalfNormal(\"sigma\", sigma=0.75)\n",
        "\n",
        "    # Expected value\n",
        "    mu = theta + beta_release_speed_norm*release_speed_norm + beta_adj_ax_norm*adj_ax_norm + beta_az_norm*az_norm\n",
        "\n",
        "    # Likelihood\n",
        "    y_obs = pm.SkewNormal(\"y_obs\", mu=mu, sigma=sigma, alpha = alpha, observed=launch_speed)"
      ],
      "metadata": {
        "id": "kxYklywfMa3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pm.model_to_graphviz(model_ev2)"
      ],
      "metadata": {
        "id": "ET9dApPUNMkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with model_ev2:\n",
        "    # Prior predictive check\n",
        "    model_ev2_trace = pm.sample_prior_predictive(samples = 100)"
      ],
      "metadata": {
        "id": "SLlo0O-SNMkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(model_ev2_trace.prior_predictive['y_obs'].squeeze().values.flatten())\n",
        "plt.xlabel('Exit Velo')\n",
        "plt.title('Exit Velo Prior Predictive Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9iwQux_8NMkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inference\n",
        "with model_ev2:\n",
        "    trace = pm.sample(draws=1000, tune=1000, cores=4, chains=4, random_seed=42)"
      ],
      "metadata": {
        "id": "g03sLF2GNMkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "az.summary(trace).sort_values('r_hat', ascending=False).head()"
      ],
      "metadata": {
        "id": "t4Y0bNaQNMkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ev2_trace.extend(trace)"
      ],
      "metadata": {
        "id": "BI0iEYrxNMkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "az.plot_trace(model_ev2_trace, var_names = ['beta_release_speed_norm', 'beta_release_speed_norm', 'beta_az_norm'], figsize=(12, 10))"
      ],
      "metadata": {
        "id": "ETquCmqUNMkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Datasets/stuff/model_ev2_trace.pkl', 'wb') as file:\n",
        "    pickle.dump(model_ev2_trace, file)"
      ],
      "metadata": {
        "id": "FW5dOWe-8jY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Datasets/stuff/model_ev2_trace.pkl', 'rb') as f:\n",
        "    model_ev2_trace = pickle.load(f)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "x5aF9NpS8jY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# posterior predictive\n",
        "with model_ev2:\n",
        "    posterior_predictive_ev = pm.sample_posterior_predictive(model_ev2_trace, extend_inferencedata=True)"
      ],
      "metadata": {
        "id": "n5ZFfWEqNMkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "az.plot_ppc(posterior_predictive_ev, group='posterior')"
      ],
      "metadata": {
        "id": "yI-ZVRJANMkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with model_ev2:\n",
        "    pm.compute_log_likelihood(model_ev2_trace)\n",
        "\n",
        "az.loo(model_ev2_trace, model_ev2)"
      ],
      "metadata": {
        "id": "1-gB28slNMkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preds"
      ],
      "metadata": {
        "id": "fhTvh5sgL1qs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_cols = [\"release_speed\", \"adj_ax\", \"az\", 'description']\n",
        "y_col = \"launch_speed\"\n",
        "\n",
        "X = df_bayes_la.select(X_cols)\n",
        "y = df_bayes_la.select(y_col)\n",
        "\n",
        "X = X.to_pandas()\n",
        "y = y.to_pandas()\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "xEV_25_all = np.zeros(y.shape[0])\n",
        "xEV_50_all = np.zeros(y.shape[0])\n",
        "xEV_75_all = np.zeros(y.shape[0])\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    # Create train/test splits\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    # Filter train data to BIP\n",
        "    X_train = X_train.loc[X_train['description'] == 'hit_into_play']\n",
        "    y_train = y_train.loc[y_train.index.isin(X_train.index)]\n",
        "\n",
        "    # Drop filter feature\n",
        "    X_train = X_train.drop(['description'], axis = 1)\n",
        "    X_test = X_test.drop(['description'], axis = 1)\n",
        "\n",
        "    # To polars\n",
        "    X_train = pl.DataFrame(X_train)\n",
        "    X_test = pl.DataFrame(X_test)\n",
        "    y_train = pl.DataFrame(y_train)\n",
        "    y_test = pl.DataFrame(y_test)\n",
        "\n",
        "    # Train Variables\n",
        "    release_speed_mean_train = X_train.select('release_speed').mean().item()\n",
        "    release_speed_std_train = X_train.select('release_speed').std().item()\n",
        "    adj_ax_mean_train = X_train.select('adj_ax').mean().item()\n",
        "    adj_ax_std_train = X_train.select('adj_ax').std().item()\n",
        "    az_mean_train = X_train.select('az').mean().item()\n",
        "    az_std_train = X_train.select('az').std().item()\n",
        "\n",
        "    X_train = X_train.with_columns(\n",
        "        release_speed_norm = (pl.col('release_speed') - pl.col('release_speed').mean())/pl.col('release_speed').std(),\n",
        "        adj_ax_norm = (pl.col('adj_ax') - pl.col('adj_ax').mean())/pl.col('adj_ax').std(),\n",
        "        az_norm = (pl.col('az') - pl.col('az').mean())/pl.col('az').std()\n",
        "    )\n",
        "    release_speed_norm_train = X_train.select('release_speed_norm').to_numpy().flatten()\n",
        "    adj_ax_norm_train = X_train.select('adj_ax_norm').to_numpy().flatten()\n",
        "    az_norm_train = X_train.select('az_norm').to_numpy().flatten()\n",
        "    launch_speed_train = y_train.to_numpy().flatten()\n",
        "\n",
        "    # Test Variables\n",
        "    X_test = X_test.with_columns(\n",
        "        release_speed_norm = (pl.col('release_speed') - release_speed_mean_train)/release_speed_std_train,\n",
        "        adj_ax_norm = (pl.col('adj_ax') - adj_ax_mean_train)/adj_ax_std_train,\n",
        "        az_norm = (pl.col('az') - az_mean_train)/az_std_train\n",
        "    )\n",
        "    release_speed_norm_test = X_test.select('release_speed_norm').to_numpy().flatten()\n",
        "    adj_ax_norm_test = X_test.select('adj_ax_norm').to_numpy().flatten()\n",
        "    az_norm_test = X_test.select('az_norm').to_numpy().flatten()\n",
        "    launch_speed_test = y_test.to_numpy().flatten()\n",
        "\n",
        "\n",
        "    with pm.Model() as model_ev_pred:\n",
        "        # Declare data\n",
        "        release_speed_norm = pm.Data('release_speed_norm', release_speed_norm_train)\n",
        "        adj_ax_norm = pm.Data('adj_ax_norm', adj_ax_norm_train)\n",
        "        az_norm = pm.Data('az_norm', az_norm_train)\n",
        "        launch_speed = pm.Data('launch_speed', launch_speed_train)\n",
        "\n",
        "        # Priors\n",
        "        theta = pm.Normal('theta', mu = 80, sigma = 10)\n",
        "        beta_release_speed_norm = pm.Normal(\"beta_release_speed_norm\", mu = 5, sigma = 10)\n",
        "        beta_adj_ax_norm = pm.Normal(\"beta_adj_ax_norm\", mu = -5, sigma = 10)\n",
        "        beta_az_norm = pm.Normal(\"beta_az_norm\", mu = 5, sigma = 10)\n",
        "        alpha = pm.Normal(\"alpha\", mu = -6, sigma = 3)\n",
        "        sigma = pm.HalfNormal(\"sigma\", sigma=0.75)\n",
        "\n",
        "        # Expected value\n",
        "        mu = theta + beta_release_speed_norm*release_speed_norm + beta_adj_ax_norm*adj_ax_norm + beta_az_norm*az_norm\n",
        "\n",
        "        # Likelihood\n",
        "        y_obs = pm.SkewNormal(\"y_obs\", mu=mu, sigma=sigma, alpha = alpha, observed=launch_speed)\n",
        "\n",
        "        # Sample posterior\n",
        "        trace = pm.sample(1000, tune=1000, cores=4, chains=4, random_seed=42)\n",
        "\n",
        "        # Predict on test set\n",
        "        pm.set_data({\n",
        "        \"release_speed_norm\": release_speed_norm_test,\n",
        "        \"adj_ax_norm\": adj_ax_norm_test,\n",
        "        \"az_norm\": az_norm_test,\n",
        "        'launch_speed': launch_speed_test\n",
        "        })\n",
        "\n",
        "        posterior_predictive = pm.sample_posterior_predictive(trace, model = model_ev_pred, var_names = ['y_obs'])\n",
        "\n",
        "        # Get percentiles\n",
        "        y_pred_samples = posterior_predictive.posterior_predictive[\"y_obs\"]\n",
        "        n_y_obs = y_pred_samples.shape[-1]\n",
        "        flat_samples = y_pred_samples.values.reshape(-1, n_y_obs)\n",
        "\n",
        "        percentiles = np.percentile(flat_samples, [25, 50, 75], axis=0)\n",
        "        xEV_25_all[test_idx] = percentiles[0]\n",
        "        xEV_50_all[test_idx] = percentiles[1]\n",
        "        xEV_75_all[test_idx] = percentiles[2]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ViCAveL8L2xr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bayes_la = df_bayes_la.with_columns(pl.Series(\"xEV_25\", xEV_25_all),\n",
        "                               pl.Series(\"xEV_50\", xEV_50_all),\n",
        "                               pl.Series(\"xEV_75\", xEV_75_all))"
      ],
      "metadata": {
        "id": "-gk8nxM-L2xr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Foul/No Foul Model"
      ],
      "metadata": {
        "id": "fR4MtOZrRfje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost model\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'foul'\n",
        "\n",
        "df_pandas = df_bayes_la.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "model = XGBClassifier()\n",
        "preds = cross_val_predict(model, X, y , cv=5, method='predict_proba')\n",
        "\n",
        "df_bayes_la = df_bayes_la.with_columns(pl.Series(\"foul_pred_xgb\", preds[:, 1]),\n",
        "                     pl.Series(\"no_foul_pred_xgb\", preds[:, 0]))"
      ],
      "metadata": {
        "id": "ITcaX6pwRxmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(n_bins = 10, data = df_bayes_la, preds = 'foul_pred_xgb', actuals = 'foul', model = 'XGBoost Foul')"
      ],
      "metadata": {
        "id": "b06J4S3SRxmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural net 2 layers\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'foul'\n",
        "\n",
        "df_pandas = df_bayes_la.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "foul_pred_all = np.zeros(y.shape[0], dtype=float)\n",
        "no_foul_pred_all = np.zeros(y.shape[0], dtype=float)\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape = (X.shape[1], )),\n",
        "        Dense(32, activation = 'relu'),\n",
        "        Dense(1, activation = 'sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer = Adam(), loss = 'binary_crossentropy')\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor = 'val_loss',\n",
        "        patience = 0,\n",
        "        restore_best_weights = True,\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train, validation_split = 0.2, batch_size = 1024, epochs = 15, callbacks = [early_stop], verbose = 1)\n",
        "\n",
        "    y_pred = model.predict(X_test_scaled).flatten()\n",
        "\n",
        "    foul_pred_all[test_idx] = y_pred\n",
        "\n",
        "df_bayes_la = df_bayes_la.with_columns(pl.Series(\"foul_pred_nn\", foul_pred_all))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5OpqAsj5Sedn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_plot(n_bins = 10, data = df_bayes_la, preds = 'foul_pred_nn', actuals = 'foul', model = 'Neural Net 2 Layers Foul')"
      ],
      "metadata": {
        "id": "nBhFNrTjSedn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bayes_la = df_bayes_la.drop(['foul_pred_xgb', 'no_foul_pred_xgb'])"
      ],
      "metadata": {
        "id": "ZSrImJa9UnkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bayes_la.write_csv('df_bayes_la.csv')\n",
        "files.download('df_bayes_la.csv')"
      ],
      "metadata": {
        "id": "TJ6e7m_bVBVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# xRV BIP Model"
      ],
      "metadata": {
        "id": "zqpWkOIRV5KD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_bayes_ev = pl.read_csv('df_bayes_la.csv')"
      ],
      "metadata": {
        "id": "KneGVykFlMLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost model\n",
        "feats = ['launch_speed', 'launch_angle']\n",
        "target = 'delta_run_exp'\n",
        "\n",
        "df_pandas = df_bip.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "model = XGBRegressor()\n",
        "preds = cross_val_predict(model, X, y , cv=5)\n",
        "\n",
        "df_bip = df_bip.with_columns(pl.Series(\"xRV_xgb\", preds))"
      ],
      "metadata": {
        "id": "kzemVcATV973"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "rmse = np.sqrt(mean_squared_error(df_bip.select('delta_run_exp'), df_bip.select('xRV_xgb')))\n",
        "\n",
        "sns.regplot(data=df_bip, x = 'xRV_xgb', y = 'delta_run_exp')\n",
        "plt.xlabel('Preds')\n",
        "plt.ylabel('Actual')\n",
        "plt.title(f'XGBoost xRV Validation \\nRMSE: {round(rmse, 4)}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WK0Q3G8tV973"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural net 4 layers\n",
        "feats = ['launch_speed', 'launch_angle']\n",
        "target = 'delta_run_exp'\n",
        "\n",
        "df_pandas = df_bip.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "\n",
        "y_pred_all = np.zeros(y.shape[0], dtype=float)\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test =  y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    model = Sequential([\n",
        "        Dense(128, activation = 'relu', input_shape = (X.shape[1], )),\n",
        "        Dense(64, activation = 'relu'),\n",
        "        Dense(32, activation = 'relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer = Adam(learning_rate = 0.0005), loss = 'mse')\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor = 'val_loss',\n",
        "        patience = 2,\n",
        "        restore_best_weights = True,\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train, validation_split = 0.2, batch_size = 1024, epochs = 15, callbacks = [early_stop], verbose = 1)\n",
        "\n",
        "    y_pred = model.predict(X_test_scaled).flatten()\n",
        "\n",
        "    y_pred_all[test_idx] = y_pred\n",
        "\n",
        "df_bip = df_bip.with_columns(pl.Series(\"xRV_pred_nn_4\", y_pred_all))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "f4fYbGQhXydR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "rmse = np.sqrt(mean_squared_error(df_bip.select('delta_run_exp'), df_bip.select('xRV_pred_nn_4')))\n",
        "\n",
        "sns.regplot(data=df_bip, x = 'xRV_pred_nn_4', y = 'delta_run_exp')\n",
        "plt.xlabel('Preds')\n",
        "plt.ylabel('Actual')\n",
        "plt.title(f'Neural Net 4 Layers xRV Validation \\nRMSE: {round(rmse, 4)}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xc5qN5QhYRab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit xRV model\n",
        "feats = ['launch_speed', 'launch_angle']\n",
        "target = 'delta_run_exp'\n",
        "\n",
        "df_bip = df_bayes_ev.filter(pl.col('description') == 'hit_into_play')\n",
        "df_pandas_fit = df_bip.to_pandas()\n",
        "df_pandas_predict = df_bayes_ev.to_pandas()\n",
        "\n",
        "model = XGBRegressor()\n",
        "model.fit(df_pandas_fit[feats], df_pandas_fit[target])"
      ],
      "metadata": {
        "id": "KMDxvCvKZZR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pandas_predict = df_bayes_ev.to_pandas()\n",
        "\n",
        "# 25th percentile launch angles\n",
        "df_pandas_predict_la25_ev25 = df_pandas_predict[['xLA_25', 'xEV_25']]\n",
        "df_pandas_predict_la25_ev25 = df_pandas_predict_la25_ev25.rename(columns = {'xLA_25': 'launch_angle', 'xEV_25': 'launch_speed'})\n",
        "preds_la25_ev25 = model.predict(df_pandas_predict_la25_ev25[feats])\n",
        "\n",
        "df_pandas_predict_la25_ev50 = df_pandas_predict[['xLA_25', 'xEV_50']]\n",
        "df_pandas_predict_la25_ev50 = df_pandas_predict_la25_ev50.rename(columns = {'xLA_25': 'launch_angle', 'xEV_50': 'launch_speed'})\n",
        "preds_la25_ev50 = model.predict(df_pandas_predict_la25_ev50[feats])\n",
        "\n",
        "df_pandas_predict_la25_ev75 = df_pandas_predict[['xLA_25', 'xEV_75']]\n",
        "df_pandas_predict_la25_ev75 = df_pandas_predict_la25_ev75.rename(columns = {'xLA_25': 'launch_angle', 'xEV_75': 'launch_speed'})\n",
        "preds_la25_ev75 = model.predict(df_pandas_predict_la25_ev75[feats])\n",
        "\n",
        "# 50th percentile launch angles\n",
        "df_pandas_predict_la50_ev25 = df_pandas_predict[['xLA_50', 'xEV_25']]\n",
        "df_pandas_predict_la50_ev25 = df_pandas_predict_la50_ev25.rename(columns = {'xLA_50': 'launch_angle', 'xEV_25': 'launch_speed'})\n",
        "preds_la50_ev25 = model.predict(df_pandas_predict_la50_ev25[feats])\n",
        "\n",
        "df_pandas_predict_la50_ev50 = df_pandas_predict[['xLA_50', 'xEV_50']]\n",
        "df_pandas_predict_la50_ev50 = df_pandas_predict_la50_ev50.rename(columns = {'xLA_50': 'launch_angle', 'xEV_50': 'launch_speed'})\n",
        "preds_la50_ev50 = model.predict(df_pandas_predict_la50_ev50[feats])\n",
        "\n",
        "df_pandas_predict_la50_ev75 = df_pandas_predict[['xLA_50', 'xEV_75']]\n",
        "df_pandas_predict_la50_ev75 = df_pandas_predict_la50_ev75.rename(columns = {'xLA_50': 'launch_angle', 'xEV_75': 'launch_speed'})\n",
        "preds_la50_ev75 = model.predict(df_pandas_predict_la50_ev75[feats])\n",
        "\n",
        "# 75th percentile launch angles\n",
        "df_pandas_predict_la75_ev25 = df_pandas_predict[['xLA_75', 'xEV_25']]\n",
        "df_pandas_predict_la75_ev25 = df_pandas_predict_la75_ev25.rename(columns = {'xLA_75': 'launch_angle', 'xEV_25': 'launch_speed'})\n",
        "preds_la75_ev25 = model.predict(df_pandas_predict_la75_ev25[feats])\n",
        "\n",
        "df_pandas_predict_la75_ev50 = df_pandas_predict[['xLA_75', 'xEV_50']]\n",
        "df_pandas_predict_la75_ev50 = df_pandas_predict_la75_ev50.rename(columns = {'xLA_75': 'launch_angle', 'xEV_50': 'launch_speed'})\n",
        "preds_la75_ev50 = model.predict(df_pandas_predict_la75_ev50[feats])\n",
        "\n",
        "df_pandas_predict_la75_ev75 = df_pandas_predict[['xLA_75', 'xEV_75']]\n",
        "df_pandas_predict_la75_ev75 = df_pandas_predict_la75_ev75.rename(columns = {'xLA_75': 'launch_angle', 'xEV_75': 'launch_speed'})\n",
        "preds_la75_ev75 = model.predict(df_pandas_predict_la75_ev75[feats])\n",
        "\n",
        "# concat to df\n",
        "df_bayes_ev = df_bayes_ev.with_columns(pl.Series(\"xRV_la25_ev25\", preds_la25_ev25),\n",
        "                             pl.Series(\"xRV_la25_ev50\", preds_la25_ev50),\n",
        "                             pl.Series(\"xRV_la25_ev75\", preds_la25_ev75),\n",
        "\n",
        "                             pl.Series(\"xRV_la50_ev25\", preds_la50_ev25),\n",
        "                             pl.Series(\"xRV_la50_ev50\", preds_la50_ev50),\n",
        "                             pl.Series(\"xRV_la50_ev75\", preds_la50_ev75),\n",
        "\n",
        "                             pl.Series(\"xRV_la75_ev25\", preds_la75_ev25),\n",
        "                             pl.Series(\"xRV_la75_ev50\", preds_la75_ev50),\n",
        "                             pl.Series(\"xRV_la75_ev75\", preds_la75_ev75))"
      ],
      "metadata": {
        "id": "lRo3vEYmmlNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2 Preds"
      ],
      "metadata": {
        "id": "I-jYMI-V4t_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pl.read_csv('/content/drive/MyDrive/Datasets/stuff/df_model1.csv')\n",
        "df_bayes_ev = pl.read_csv('/content/drive/MyDrive/Datasets/stuff/df_bayes_ev.csv')"
      ],
      "metadata": {
        "id": "4OBRAF5tLoKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# joining dfs\n",
        "cols = ['game_year', 'player_name', 'pitch_type', 'release_pos_x', 'release_pos_z', 'release_pos_y', 'pfx_x', 'pfx_z', 'spin_axis', 'release_speed', 'release_extension', 'arm_angle', 'release_spin_rate', 'ax', 'ay', 'az']\n",
        "filter_cols = ['called_strike', 'called_ball', 'called_hbp', 'whiff']\n",
        "df_join = df.select(cols + filter_cols)\n",
        "\n",
        "df_bayes_ev = df_bayes_ev.join(df_join, on = cols, how = 'left')"
      ],
      "metadata": {
        "id": "1PqT86Mg6GdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting non foul preds\n",
        "df_bayes_ev = df_bayes_ev.with_columns(\n",
        "    no_foul_pred_nn = 1 - pl.col('foul_pred_nn')\n",
        ")\n",
        "\n",
        "# getting event avg run values\n",
        "called_strike = df_bayes_ev.filter(pl.col('called_strike') == 1)['delta_run_exp'].mean()\n",
        "called_ball = df_bayes_ev.filter(pl.col('called_ball') == 1)['delta_run_exp'].mean()\n",
        "called_hbp = df_bayes_ev.filter(pl.col('called_hbp') == 1)['delta_run_exp'].mean()\n",
        "\n",
        "whiff = df_bayes_ev.filter(pl.col('whiff') == 1)['delta_run_exp'].mean()\n",
        "\n",
        "foul = df_bayes_ev.filter(pl.col('foul') == 1)['delta_run_exp'].mean()"
      ],
      "metadata": {
        "id": "AUIAPmNr47dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generating preds\n",
        "df_bayes_ev = df_bayes_ev.with_columns(\n",
        "    xRV_model2 =\n",
        "    pl.col('take_pred_xgb')*pl.col('called_strike_pred_nn')*called_strike +\n",
        "    pl.col('take_pred_xgb')*pl.col('called_ball_pred_nn')*called_ball +\n",
        "    pl.col('take_pred_xgb')*pl.col('called_hbp_pred_nn')*called_hbp +\n",
        "\n",
        "    pl.col('swing_pred_xgb')*pl.col('whiff_pred_xgb')*whiff +\n",
        "\n",
        "    pl.col('swing_pred_xgb')*pl.col('contact_pred_xgb')*pl.col('foul_pred_nn')*foul +\n",
        "\n",
        "    pl.col('swing_pred_xgb')*pl.col('contact_pred_xgb')*pl.col('no_foul_pred_nn')*0.25*0.25*pl.col('xRV_la25_ev25') +\n",
        "    pl.col('swing_pred_xgb')*pl.col('contact_pred_xgb')*pl.col('no_foul_pred_nn')*0.25*0.50*pl.col('xRV_la25_ev50') +\n",
        "    pl.col('swing_pred_xgb')*pl.col('contact_pred_xgb')*pl.col('no_foul_pred_nn')*0.25*0.25*pl.col('xRV_la25_ev75') +\n",
        "\n",
        "    pl.col('swing_pred_xgb')*pl.col('contact_pred_xgb')*pl.col('no_foul_pred_nn')*0.50*0.25*pl.col('xRV_la50_ev25') +\n",
        "    pl.col('swing_pred_xgb')*pl.col('contact_pred_xgb')*pl.col('no_foul_pred_nn')*0.50*0.50*pl.col('xRV_la50_ev50') +\n",
        "    pl.col('swing_pred_xgb')*pl.col('contact_pred_xgb')*pl.col('no_foul_pred_nn')*0.50*0.25*pl.col('xRV_la50_ev75') +\n",
        "\n",
        "    pl.col('swing_pred_xgb')*pl.col('contact_pred_xgb')*pl.col('no_foul_pred_nn')*0.25*0.25*pl.col('xRV_la75_ev25') +\n",
        "    pl.col('swing_pred_xgb')*pl.col('contact_pred_xgb')*pl.col('no_foul_pred_nn')*0.25*0.50*pl.col('xRV_la75_ev50') +\n",
        "    pl.col('swing_pred_xgb')*pl.col('contact_pred_xgb')*pl.col('no_foul_pred_nn')*0.25*0.25*pl.col('xRV_la75_ev75')\n",
        ")"
      ],
      "metadata": {
        "id": "FlxcUBq747dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model 2 pred distribution\n",
        "sns.histplot(df_bayes_ev.select(pl.col('xRV_model2')))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rswaf_vc_ajx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model 2 best by year\n",
        "df_bayes_ev.group_by(pl.col('game_year'), pl.col('player_name')).agg(pl.col('xRV_model2').mean()).sort('xRV_model2', descending = False).head(10)"
      ],
      "metadata": {
        "id": "VDFbeOFU_ajx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model 2 best pitches by year\n",
        " (df_bayes_ev\n",
        "    .group_by(pl.col('game_year'), pl.col('player_name'), pl.col('pitch_type'))\n",
        "    .agg(pl.col('xRV_model2').mean())\n",
        "    .sort('xRV_model2', descending = False).head(10)\n",
        ")"
      ],
      "metadata": {
        "id": "Xu00opEL_ajx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_corr = pl.read_csv('/content/drive/MyDrive/Datasets/stuff/corr_df.csv')"
      ],
      "metadata": {
        "id": "jZSTabE4BLUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# regenerating baseline preds on filtered dataset\n",
        "feats = ['righty', 'release_pos_x', 'release_pos_z', 'release_extension', 'arm_angle', 'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'secondary_velo_differential', 'secondary_vert_differential', 'secondary_horz_differential']\n",
        "target = 'delta_run_exp'\n",
        "\n",
        "df_pandas = df_bayes_ev.to_pandas()\n",
        "X = df_pandas[feats]\n",
        "y = df_pandas[target]\n",
        "model = XGBRegressor()\n",
        "preds = cross_val_predict(model, X, y , cv=5, method='predict')\n",
        "\n",
        "df_bayes_ev = df_bayes_ev.with_columns(pl.Series(\"xRV_baseline\", preds))"
      ],
      "metadata": {
        "id": "IdajAJ4aDdK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# putting on stuff+ scale\n",
        "df_bayes_ev = df_bayes_ev.with_columns([\n",
        "    (-((pl.col(\"xRV_baseline\") - pl.col(\"xRV_baseline\").mean()) / pl.col(\"xRV_baseline\").std()) * 10 + 100).alias(\"Baseline_Stuff+\"),\n",
        "    (-((pl.col(\"xRV_model1\") - pl.col(\"xRV_model1\").mean()) / pl.col(\"xRV_model1\").std()) * 10 + 100).alias(\"Model1_Stuff+\"),\n",
        "    (-((pl.col(\"xRV_model2\") - pl.col(\"xRV_model2\").mean()) / pl.col(\"xRV_model2\").std()) * 10 + 100).alias(\"Model2_Stuff+\")\n",
        "])"
      ],
      "metadata": {
        "id": "UaYkW9H5Evx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bayes_ev.write_csv('df_bayes_ev.csv')\n",
        "files.download('df_bayes_ev.csv')"
      ],
      "metadata": {
        "id": "qBBHATSoMVpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model 2 worst by year\n",
        "df_bayes_ev.group_by(pl.col('game_year'), pl.col('player_name')).agg(pl.col('Model2_Stuff+').mean()).sort('Model2_Stuff+', descending = False).head(10)"
      ],
      "metadata": {
        "id": "lA7uORPLF0X6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(df_bayes_ev\n",
        "    .filter(pl.col('player_name') == 'Skenes, Paul')\n",
        "    .group_by(pl.col('game_year'), pl.col('player_name'), pl.col('pitch_type'))\n",
        "    .agg(pl.col('Model2_Stuff+').mean())\n",
        "    .sort('Model2_Stuff+', descending = True).head(10)\n",
        ")"
      ],
      "metadata": {
        "id": "0n_aNi1QGrT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model 2 best pitches by year\n",
        " (df_bayes_ev\n",
        "    .group_by(pl.col('game_year'), pl.col('player_name'), pl.col('pitch_type'))\n",
        "    .agg(pl.col('Model2_Stuff+').mean())\n",
        "    .sort('Model2_Stuff+', descending = True).head(10)\n",
        ")"
      ],
      "metadata": {
        "id": "uMVddyPUF0X6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model 1 best pitches by year\n",
        " (df_bayes_ev\n",
        "    .group_by(pl.col('game_year'), pl.col('player_name'), pl.col('pitch_type'))\n",
        "    .agg(pl.col('Model1_Stuff+').mean())\n",
        "    .sort('Model1_Stuff+', descending = True).head(10)\n",
        ")"
      ],
      "metadata": {
        "id": "H6M0IUQMGUt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# baseline best pitches by year\n",
        " (df_bayes_ev\n",
        "    .group_by(pl.col('game_year'), pl.col('player_name'), pl.col('pitch_type'))\n",
        "    .agg(pl.col('Baseline_Stuff+').mean())\n",
        "    .sort('Baseline_Stuff+', descending = True).head(10)\n",
        ")"
      ],
      "metadata": {
        "id": "1L4fLYV6RhEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# correlations for filtered dataset\n",
        "\n",
        "# get average stuff for each pitcher\n",
        "mean_stuff = df_bayes_ev.group_by(pl.col('game_year'), pl.col('player_name')).agg(pl.col('Baseline_Stuff+').mean())\n",
        "mean_stuff1 = df_bayes_ev.group_by(pl.col('game_year'), pl.col('player_name')).agg(pl.col('Model1_Stuff+').mean())\n",
        "mean_stuff2 = df_bayes_ev.group_by(pl.col('game_year'), pl.col('player_name')).agg(pl.col('Model2_Stuff+').mean())\n",
        "# join to corr df\n",
        "df_corr = df_corr.join(mean_stuff, left_on = ['Season', 'names'], right_on = ['game_year', 'player_name'], how='inner')\n",
        "df_corr = df_corr.join(mean_stuff1, left_on = ['Season', 'names'], right_on = ['game_year', 'player_name'], how='inner')\n",
        "df_corr = df_corr.join(mean_stuff2, left_on = ['Season', 'names'], right_on = ['game_year', 'player_name'], how='inner')\n",
        "# rename for clarity\n",
        "df_corr = df_corr.rename({'Stuff+': 'Fangraphs_Stuff+'})\n",
        "\n",
        "# create corr matrix\n",
        "y_vars = ['ERA_next', 'FIP_next', 'xFIP_next', 'SIERA_next']\n",
        "x_vars = ['ERA', 'FIP', 'xFIP', 'SIERA', 'botStf', 'Fangraphs_Stuff+', 'Baseline_Stuff+', 'Model1_Stuff+', 'Model2_Stuff+']\n",
        "\n",
        "correlations = []\n",
        "\n",
        "for x in x_vars:\n",
        "    row = []\n",
        "    for y in y_vars:\n",
        "        corr = df_corr.select(pl.corr(x, y)).item()\n",
        "        row.append(abs(corr))\n",
        "    correlations.append(row)\n",
        "\n",
        "corr_pd = pd.DataFrame((correlations), index=x_vars, columns=y_vars)\n",
        "\n",
        "# plot corr matrix\n",
        "sns.heatmap(corr_pd, annot=True, vmin = 0.2, vmax = 0.65, cmap=\"coolwarm\", fmt = '.2f')\n",
        "plt.title(f\"Stuff+ Correlation Matrix (Min 100 IP)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MhNDTTLBBwsp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}